{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import butterflies\n",
    "from dwt_transform import DWT2Numpy\n",
    "from network import Net, run\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_epoch_info_from_file(file):\n",
    "    epochs = []\n",
    "    accuracies = []\n",
    "    test_losses = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.lower()\n",
    "            if \"epoch\" in line:\n",
    "                _, epoch_num = line.split()\n",
    "                epochs.append(epoch_num)\n",
    "            if \"accuracy\" in line:\n",
    "                _, accuracy_raw, _, _, loss_raw = line.split()\n",
    "                accuracy = float(accuracy_raw.strip(\"%,\"))\n",
    "                loss_val = float(loss_raw)\n",
    "                accuracies.append(accuracy)\n",
    "                test_losses.append(loss_val)\n",
    "    return epochs, (accuracies, test_losses)\n",
    "                \n",
    "def _get_fig_ax(fig=None, ax=None):\n",
    "    if fig is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca()\n",
    "    if ax is None:\n",
    "        ax = fig.gca()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_file(file, label, fig=None, ax=None):\n",
    "    fig, ax = _get_fig_ax(fig, ax)\n",
    "    epochs, (accuracy, _) = get_epoch_info_from_file(file)\n",
    "    ax.plot(epochs, accuracy, label=label)\n",
    "    return fig, ax\n",
    "\n",
    "def plot_epoch_info(original_file, wav_files, dataset_str, wav_strs):\n",
    "    fig, ax = plot_file(original_file, dataset_str)\n",
    "    for wav_label, file in zip(wav_strs, wav_files):\n",
    "        plot_file(file, dataset_str + \": \" + wav_label, fig=fig, ax=ax)\n",
    "    fig.legend(loc=\"center right\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dwt = transforms.Compose([DWT2Numpy(\"haar\"), transforms.ToTensor()])\n",
    "\n",
    "train_data_dwt = butterflies.ButterflyDataset(\"../data\", datasplit=\"train\", transform=transform_dwt)\n",
    "val_data_dwt = butterflies.ButterflyDataset(\"../data\", datasplit=\"valid\", transform=transform_dwt)\n",
    "test_data_dwt = butterflies.ButterflyDataset(\"../data\", datasplit=\"test\", transform=transform_dwt)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader_dwt = DataLoader(\n",
    "    train_data_dwt, batch_size=batch_size, shuffle=True, num_workers=4#, pin_memory=True\n",
    ")\n",
    "val_loader_dwt = DataLoader(\n",
    "    val_data_dwt, batch_size=batch_size, shuffle=False, num_workers=2#, pin_memory=True\n",
    ")\n",
    "test_loader_dwt = DataLoader(\n",
    "    test_data_dwt, batch_size=batch_size, shuffle=False, num_workers=2#, pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = butterflies.ButterflyDataset(\"../data\", datasplit=\"train\", transform=transform)\n",
    "val_data = butterflies.ButterflyDataset(\"../data\", datasplit=\"valid\", transform=transform)\n",
    "test_data = butterflies.ButterflyDataset(\"../data\", datasplit=\"test\", transform=transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(\n",
    "    conv_layers=((12, 5), (32, 5), (64, 5)),\n",
    "    linear_layers=(512, 256),\n",
    "    output_size=len(train_data.classes),\n",
    "    output_activation=lambda x: torch.log_softmax(x, dim=1),\n",
    ")\n",
    "net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, dampening=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dwt = Net(\n",
    "    conv_layers=((32, 5), (64, 5), (128, 3)),\n",
    "    linear_layers=(512, 256),\n",
    "    output_size=len(train_data.classes),\n",
    "    output_activation=lambda x: torch.log_softmax(x, dim=1),\n",
    ")\n",
    "# net_dwt = Net(\n",
    "#     conv_layers=(),\n",
    "#     linear_layers=(1024,),\n",
    "#     output_size=len(train_data.classes),\n",
    "#     output_activation=torch.sigmoid,\n",
    "# )\n",
    "net_dwt.to(device)\n",
    "optimizer_dwt = optim.SGD(net_dwt.parameters(), lr=0.01, momentum=0.9, dampening=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out_normal\n",
    "run(train_loader, val_loader, net, loss_fn, optimizer, device, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.601039  [    0/12639]\n",
      "loss: 4.605757  [ 1216/12639]\n",
      "loss: 4.598876  [ 2432/12639]\n",
      "loss: 4.612963  [ 3648/12639]\n",
      "loss: 4.608137  [ 4864/12639]\n",
      "loss: 4.606425  [ 6080/12639]\n",
      "loss: 4.590519  [ 7296/12639]\n",
      "loss: 4.572356  [ 8512/12639]\n",
      "loss: 4.588650  [ 9728/12639]\n",
      "loss: 4.573944  [10944/12639]\n",
      "loss: 4.513321  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 4.487863 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.408611  [    0/12639]\n",
      "loss: 4.373014  [ 1216/12639]\n",
      "loss: 4.346182  [ 2432/12639]\n",
      "loss: 4.092402  [ 3648/12639]\n",
      "loss: 4.320557  [ 4864/12639]\n",
      "loss: 4.218812  [ 6080/12639]\n",
      "loss: 4.046138  [ 7296/12639]\n",
      "loss: 3.992087  [ 8512/12639]\n",
      "loss: 3.820941  [ 9728/12639]\n",
      "loss: 3.805957  [10944/12639]\n",
      "loss: 3.778543  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 3.418865 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.491564  [    0/12639]\n",
      "loss: 3.560325  [ 1216/12639]\n",
      "loss: 3.052645  [ 2432/12639]\n",
      "loss: 3.116849  [ 3648/12639]\n",
      "loss: 3.496217  [ 4864/12639]\n",
      "loss: 3.268255  [ 6080/12639]\n",
      "loss: 2.629365  [ 7296/12639]\n",
      "loss: 3.108268  [ 8512/12639]\n",
      "loss: 2.600067  [ 9728/12639]\n",
      "loss: 2.795663  [10944/12639]\n",
      "loss: 2.477194  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 2.684526 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.512794  [    0/12639]\n",
      "loss: 2.342113  [ 1216/12639]\n",
      "loss: 2.302550  [ 2432/12639]\n",
      "loss: 2.264657  [ 3648/12639]\n",
      "loss: 2.365562  [ 4864/12639]\n",
      "loss: 2.637008  [ 6080/12639]\n",
      "loss: 2.242734  [ 7296/12639]\n",
      "loss: 1.898323  [ 8512/12639]\n",
      "loss: 2.486460  [ 9728/12639]\n",
      "loss: 2.431553  [10944/12639]\n",
      "loss: 1.931697  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 42.4%, Avg loss: 2.216260 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.419324  [    0/12639]\n",
      "loss: 1.838739  [ 1216/12639]\n",
      "loss: 1.877777  [ 2432/12639]\n",
      "loss: 1.429402  [ 3648/12639]\n",
      "loss: 1.839482  [ 4864/12639]\n",
      "loss: 1.910835  [ 6080/12639]\n",
      "loss: 1.588896  [ 7296/12639]\n",
      "loss: 1.727090  [ 8512/12639]\n",
      "loss: 1.691877  [ 9728/12639]\n",
      "loss: 1.703855  [10944/12639]\n",
      "loss: 1.749116  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.896516 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.321079  [    0/12639]\n",
      "loss: 1.077964  [ 1216/12639]\n",
      "loss: 1.384203  [ 2432/12639]\n",
      "loss: 1.117212  [ 3648/12639]\n",
      "loss: 1.662300  [ 4864/12639]\n",
      "loss: 1.213900  [ 6080/12639]\n",
      "loss: 1.022158  [ 7296/12639]\n",
      "loss: 1.140042  [ 8512/12639]\n",
      "loss: 0.944582  [ 9728/12639]\n",
      "loss: 1.442334  [10944/12639]\n",
      "loss: 1.419906  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.515348 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.718197  [    0/12639]\n",
      "loss: 0.643619  [ 1216/12639]\n",
      "loss: 1.140461  [ 2432/12639]\n",
      "loss: 0.934625  [ 3648/12639]\n",
      "loss: 0.739549  [ 4864/12639]\n",
      "loss: 1.001641  [ 6080/12639]\n",
      "loss: 0.725708  [ 7296/12639]\n",
      "loss: 0.717225  [ 8512/12639]\n",
      "loss: 0.719768  [ 9728/12639]\n",
      "loss: 0.618955  [10944/12639]\n",
      "loss: 0.877454  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 1.717464 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.505547  [    0/12639]\n",
      "loss: 0.537711  [ 1216/12639]\n",
      "loss: 0.441678  [ 2432/12639]\n",
      "loss: 0.344756  [ 3648/12639]\n",
      "loss: 0.655911  [ 4864/12639]\n",
      "loss: 0.282549  [ 6080/12639]\n",
      "loss: 0.555427  [ 7296/12639]\n",
      "loss: 0.651029  [ 8512/12639]\n",
      "loss: 0.489133  [ 9728/12639]\n",
      "loss: 0.640518  [10944/12639]\n",
      "loss: 0.590269  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.865276 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.427614  [    0/12639]\n",
      "loss: 0.127262  [ 1216/12639]\n",
      "loss: 0.182708  [ 2432/12639]\n",
      "loss: 0.407487  [ 3648/12639]\n",
      "loss: 0.589689  [ 4864/12639]\n",
      "loss: 0.314843  [ 6080/12639]\n",
      "loss: 0.327850  [ 7296/12639]\n",
      "loss: 0.144068  [ 8512/12639]\n",
      "loss: 0.749303  [ 9728/12639]\n",
      "loss: 0.355170  [10944/12639]\n",
      "loss: 0.217268  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 2.057204 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.178506  [    0/12639]\n",
      "loss: 0.157723  [ 1216/12639]\n",
      "loss: 0.256807  [ 2432/12639]\n",
      "loss: 0.107011  [ 3648/12639]\n",
      "loss: 0.216195  [ 4864/12639]\n",
      "loss: 0.149526  [ 6080/12639]\n",
      "loss: 0.171138  [ 7296/12639]\n",
      "loss: 0.400896  [ 8512/12639]\n",
      "loss: 0.380504  [ 9728/12639]\n",
      "loss: 0.338627  [10944/12639]\n",
      "loss: 0.466341  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 2.134465 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.273046  [    0/12639]\n",
      "loss: 0.103830  [ 1216/12639]\n",
      "loss: 0.174713  [ 2432/12639]\n",
      "loss: 0.085223  [ 3648/12639]\n",
      "loss: 0.180688  [ 4864/12639]\n",
      "loss: 0.150899  [ 6080/12639]\n",
      "loss: 0.327400  [ 7296/12639]\n",
      "loss: 0.067467  [ 8512/12639]\n",
      "loss: 0.297907  [ 9728/12639]\n",
      "loss: 0.062096  [10944/12639]\n",
      "loss: 0.144935  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 2.056358 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.148201  [    0/12639]\n",
      "loss: 0.188171  [ 1216/12639]\n",
      "loss: 0.230196  [ 2432/12639]\n",
      "loss: 0.044632  [ 3648/12639]\n",
      "loss: 0.173785  [ 4864/12639]\n",
      "loss: 0.076213  [ 6080/12639]\n",
      "loss: 0.123598  [ 7296/12639]\n",
      "loss: 0.057967  [ 8512/12639]\n",
      "loss: 0.157457  [ 9728/12639]\n",
      "loss: 0.062517  [10944/12639]\n",
      "loss: 0.050535  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.0%, Avg loss: 2.144148 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.085402  [    0/12639]\n",
      "loss: 0.095380  [ 1216/12639]\n",
      "loss: 0.053744  [ 2432/12639]\n",
      "loss: 0.022583  [ 3648/12639]\n",
      "loss: 0.117187  [ 4864/12639]\n",
      "loss: 0.034181  [ 6080/12639]\n",
      "loss: 0.030050  [ 7296/12639]\n",
      "loss: 0.038403  [ 8512/12639]\n",
      "loss: 0.026332  [ 9728/12639]\n",
      "loss: 0.053755  [10944/12639]\n",
      "loss: 0.156633  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 2.471865 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.011400  [    0/12639]\n",
      "loss: 0.011085  [ 1216/12639]\n",
      "loss: 0.030227  [ 2432/12639]\n",
      "loss: 0.004966  [ 3648/12639]\n",
      "loss: 0.020052  [ 4864/12639]\n",
      "loss: 0.058451  [ 6080/12639]\n",
      "loss: 0.036652  [ 7296/12639]\n",
      "loss: 0.031395  [ 8512/12639]\n",
      "loss: 0.019338  [ 9728/12639]\n",
      "loss: 0.081258  [10944/12639]\n",
      "loss: 0.064138  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 2.805328 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.021697  [    0/12639]\n",
      "loss: 0.023927  [ 1216/12639]\n",
      "loss: 0.097701  [ 2432/12639]\n",
      "loss: 0.051393  [ 3648/12639]\n",
      "loss: 0.052165  [ 4864/12639]\n",
      "loss: 0.068569  [ 6080/12639]\n",
      "loss: 0.024662  [ 7296/12639]\n",
      "loss: 0.109985  [ 8512/12639]\n",
      "loss: 0.100361  [ 9728/12639]\n",
      "loss: 0.129110  [10944/12639]\n",
      "loss: 0.129563  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 2.415359 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.009682  [    0/12639]\n",
      "loss: 0.013420  [ 1216/12639]\n",
      "loss: 0.005564  [ 2432/12639]\n",
      "loss: 0.077033  [ 3648/12639]\n",
      "loss: 0.028945  [ 4864/12639]\n",
      "loss: 0.067971  [ 6080/12639]\n",
      "loss: 0.054092  [ 7296/12639]\n",
      "loss: 0.021685  [ 8512/12639]\n",
      "loss: 0.037158  [ 9728/12639]\n",
      "loss: 0.053488  [10944/12639]\n",
      "loss: 0.026097  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.2%, Avg loss: 2.340912 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.025574  [    0/12639]\n",
      "loss: 0.012998  [ 1216/12639]\n",
      "loss: 0.003771  [ 2432/12639]\n",
      "loss: 0.012797  [ 3648/12639]\n",
      "loss: 0.008264  [ 4864/12639]\n",
      "loss: 0.002452  [ 6080/12639]\n",
      "loss: 0.001020  [ 7296/12639]\n",
      "loss: 0.003302  [ 8512/12639]\n",
      "loss: 0.006665  [ 9728/12639]\n",
      "loss: 0.001113  [10944/12639]\n",
      "loss: 0.043572  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 2.788400 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.095180  [    0/12639]\n",
      "loss: 0.006533  [ 1216/12639]\n",
      "loss: 0.003606  [ 2432/12639]\n",
      "loss: 0.000615  [ 3648/12639]\n",
      "loss: 0.029093  [ 4864/12639]\n",
      "loss: 0.011243  [ 6080/12639]\n",
      "loss: 0.013038  [ 7296/12639]\n",
      "loss: 0.006400  [ 8512/12639]\n",
      "loss: 0.001294  [ 9728/12639]\n",
      "loss: 0.001424  [10944/12639]\n",
      "loss: 0.073221  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 2.713368 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.007315  [    0/12639]\n",
      "loss: 0.050757  [ 1216/12639]\n",
      "loss: 0.064559  [ 2432/12639]\n",
      "loss: 0.048898  [ 3648/12639]\n",
      "loss: 0.000682  [ 4864/12639]\n",
      "loss: 0.001041  [ 6080/12639]\n",
      "loss: 0.000455  [ 7296/12639]\n",
      "loss: 0.000307  [ 8512/12639]\n",
      "loss: 0.003350  [ 9728/12639]\n",
      "loss: 0.005616  [10944/12639]\n",
      "loss: 0.001447  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 2.921555 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.002098  [    0/12639]\n",
      "loss: 0.016021  [ 1216/12639]\n",
      "loss: 0.006097  [ 2432/12639]\n",
      "loss: 0.002259  [ 3648/12639]\n",
      "loss: 0.006726  [ 4864/12639]\n",
      "loss: 0.011099  [ 6080/12639]\n",
      "loss: 0.002718  [ 7296/12639]\n",
      "loss: 0.033987  [ 8512/12639]\n",
      "loss: 0.018992  [ 9728/12639]\n",
      "loss: 0.002496  [10944/12639]\n",
      "loss: 0.003650  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 2.722275 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.003074  [    0/12639]\n",
      "loss: 0.043529  [ 1216/12639]\n",
      "loss: 0.008558  [ 2432/12639]\n",
      "loss: 0.002345  [ 3648/12639]\n",
      "loss: 0.001525  [ 4864/12639]\n",
      "loss: 0.000578  [ 6080/12639]\n",
      "loss: 0.001364  [ 7296/12639]\n",
      "loss: 0.034194  [ 8512/12639]\n",
      "loss: 0.085734  [ 9728/12639]\n",
      "loss: 0.019987  [10944/12639]\n",
      "loss: 0.001469  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 2.790382 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.002427  [    0/12639]\n",
      "loss: 0.028079  [ 1216/12639]\n",
      "loss: 0.021391  [ 2432/12639]\n",
      "loss: 0.005993  [ 3648/12639]\n",
      "loss: 0.041614  [ 4864/12639]\n",
      "loss: 0.003991  [ 6080/12639]\n",
      "loss: 0.213582  [ 7296/12639]\n",
      "loss: 0.095036  [ 8512/12639]\n",
      "loss: 0.047656  [ 9728/12639]\n",
      "loss: 0.001831  [10944/12639]\n",
      "loss: 0.067879  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 2.450355 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.004584  [    0/12639]\n",
      "loss: 0.003476  [ 1216/12639]\n",
      "loss: 0.001175  [ 2432/12639]\n",
      "loss: 0.034039  [ 3648/12639]\n",
      "loss: 0.004241  [ 4864/12639]\n",
      "loss: 0.005295  [ 6080/12639]\n",
      "loss: 0.001331  [ 7296/12639]\n",
      "loss: 0.002356  [ 8512/12639]\n",
      "loss: 0.000615  [ 9728/12639]\n",
      "loss: 0.000713  [10944/12639]\n",
      "loss: 0.723608  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 2.758255 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.024802  [    0/12639]\n",
      "loss: 0.002543  [ 1216/12639]\n",
      "loss: 0.039883  [ 2432/12639]\n",
      "loss: 0.001659  [ 3648/12639]\n",
      "loss: 0.000288  [ 4864/12639]\n",
      "loss: 0.032355  [ 6080/12639]\n",
      "loss: 0.000939  [ 7296/12639]\n",
      "loss: 0.000547  [ 8512/12639]\n",
      "loss: 0.002176  [ 9728/12639]\n",
      "loss: 0.000500  [10944/12639]\n",
      "loss: 0.000226  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 2.640139 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.000963  [    0/12639]\n",
      "loss: 0.001538  [ 1216/12639]\n",
      "loss: 0.000312  [ 2432/12639]\n",
      "loss: 0.000238  [ 3648/12639]\n",
      "loss: 0.000254  [ 4864/12639]\n",
      "loss: 0.000132  [ 6080/12639]\n",
      "loss: 0.000237  [ 7296/12639]\n",
      "loss: 0.000386  [ 8512/12639]\n",
      "loss: 0.000109  [ 9728/12639]\n",
      "loss: 0.001009  [10944/12639]\n",
      "loss: 0.003230  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 2.734805 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.000344  [    0/12639]\n",
      "loss: 0.000980  [ 1216/12639]\n",
      "loss: 0.000375  [ 2432/12639]\n",
      "loss: 0.004864  [ 3648/12639]\n",
      "loss: 0.001161  [ 4864/12639]\n",
      "loss: 0.030444  [ 6080/12639]\n",
      "loss: 0.008935  [ 7296/12639]\n",
      "loss: 0.006414  [ 8512/12639]\n",
      "loss: 0.005435  [ 9728/12639]\n",
      "loss: 0.003585  [10944/12639]\n",
      "loss: 0.016921  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 2.545733 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.079406  [    0/12639]\n",
      "loss: 0.089002  [ 1216/12639]\n",
      "loss: 0.003509  [ 2432/12639]\n",
      "loss: 0.008108  [ 3648/12639]\n",
      "loss: 0.004868  [ 4864/12639]\n",
      "loss: 0.032005  [ 6080/12639]\n",
      "loss: 0.013563  [ 7296/12639]\n",
      "loss: 0.099814  [ 8512/12639]\n",
      "loss: 0.003613  [ 9728/12639]\n",
      "loss: 0.004698  [10944/12639]\n",
      "loss: 0.003733  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 2.450451 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/12639]\n",
      "loss: 0.001305  [ 1216/12639]\n",
      "loss: 0.001207  [ 2432/12639]\n",
      "loss: 0.000618  [ 3648/12639]\n",
      "loss: 0.001033  [ 4864/12639]\n",
      "loss: 0.000424  [ 6080/12639]\n",
      "loss: 0.005318  [ 7296/12639]\n",
      "loss: 0.000906  [ 8512/12639]\n",
      "loss: 0.000263  [ 9728/12639]\n",
      "loss: 0.001599  [10944/12639]\n",
      "loss: 0.000139  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 2.549370 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.000113  [    0/12639]\n",
      "loss: 0.000103  [ 1216/12639]\n",
      "loss: 0.000383  [ 2432/12639]\n",
      "loss: 0.000927  [ 3648/12639]\n",
      "loss: 0.000164  [ 4864/12639]\n",
      "loss: 0.000027  [ 6080/12639]\n",
      "loss: 0.000085  [ 7296/12639]\n",
      "loss: 0.000334  [ 8512/12639]\n",
      "loss: 0.000103  [ 9728/12639]\n",
      "loss: 0.000546  [10944/12639]\n",
      "loss: 0.000347  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 2.621202 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000017  [    0/12639]\n",
      "loss: 0.000041  [ 1216/12639]\n",
      "loss: 0.000062  [ 2432/12639]\n",
      "loss: 0.000072  [ 3648/12639]\n",
      "loss: 0.000077  [ 4864/12639]\n",
      "loss: 0.000114  [ 6080/12639]\n",
      "loss: 0.000112  [ 7296/12639]\n",
      "loss: 0.000117  [ 8512/12639]\n",
      "loss: 0.000025  [ 9728/12639]\n",
      "loss: 0.000081  [10944/12639]\n",
      "loss: 0.000623  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 2.754007 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.002064  [    0/12639]\n",
      "loss: 0.000279  [ 1216/12639]\n",
      "loss: 0.000174  [ 2432/12639]\n",
      "loss: 0.000099  [ 3648/12639]\n",
      "loss: 0.000115  [ 4864/12639]\n",
      "loss: 0.000080  [ 6080/12639]\n",
      "loss: 0.000532  [ 7296/12639]\n",
      "loss: 0.000067  [ 8512/12639]\n",
      "loss: 0.000229  [ 9728/12639]\n",
      "loss: 0.000235  [10944/12639]\n",
      "loss: 0.000034  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.584492 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.000037  [    0/12639]\n",
      "loss: 0.000010  [ 1216/12639]\n",
      "loss: 0.000075  [ 2432/12639]\n",
      "loss: 0.000134  [ 3648/12639]\n",
      "loss: 0.000025  [ 4864/12639]\n",
      "loss: 0.000099  [ 6080/12639]\n",
      "loss: 0.000109  [ 7296/12639]\n",
      "loss: 0.000035  [ 8512/12639]\n",
      "loss: 0.000044  [ 9728/12639]\n",
      "loss: 0.000137  [10944/12639]\n",
      "loss: 0.000109  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.611427 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.000207  [    0/12639]\n",
      "loss: 0.000030  [ 1216/12639]\n",
      "loss: 0.000024  [ 2432/12639]\n",
      "loss: 0.000031  [ 3648/12639]\n",
      "loss: 0.000023  [ 4864/12639]\n",
      "loss: 0.000039  [ 6080/12639]\n",
      "loss: 0.000017  [ 7296/12639]\n",
      "loss: 0.000037  [ 8512/12639]\n",
      "loss: 0.000057  [ 9728/12639]\n",
      "loss: 0.000034  [10944/12639]\n",
      "loss: 0.000135  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 2.634621 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.000057  [    0/12639]\n",
      "loss: 0.000037  [ 1216/12639]\n",
      "loss: 0.000037  [ 2432/12639]\n",
      "loss: 0.000071  [ 3648/12639]\n",
      "loss: 0.000039  [ 4864/12639]\n",
      "loss: 0.000047  [ 6080/12639]\n",
      "loss: 0.000033  [ 7296/12639]\n",
      "loss: 0.000149  [ 8512/12639]\n",
      "loss: 0.000025  [ 9728/12639]\n",
      "loss: 0.000036  [10944/12639]\n",
      "loss: 0.000017  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.655443 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.000059  [    0/12639]\n",
      "loss: 0.000052  [ 1216/12639]\n",
      "loss: 0.000025  [ 2432/12639]\n",
      "loss: 0.000029  [ 3648/12639]\n",
      "loss: 0.000079  [ 4864/12639]\n",
      "loss: 0.000026  [ 6080/12639]\n",
      "loss: 0.000006  [ 7296/12639]\n",
      "loss: 0.000008  [ 8512/12639]\n",
      "loss: 0.000040  [ 9728/12639]\n",
      "loss: 0.000021  [10944/12639]\n",
      "loss: 0.000065  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.673442 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/12639]\n",
      "loss: 0.000037  [ 1216/12639]\n",
      "loss: 0.000075  [ 2432/12639]\n",
      "loss: 0.000018  [ 3648/12639]\n",
      "loss: 0.000024  [ 4864/12639]\n",
      "loss: 0.000039  [ 6080/12639]\n",
      "loss: 0.000005  [ 7296/12639]\n",
      "loss: 0.000021  [ 8512/12639]\n",
      "loss: 0.000018  [ 9728/12639]\n",
      "loss: 0.000027  [10944/12639]\n",
      "loss: 0.000061  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 2.690048 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/12639]\n",
      "loss: 0.000033  [ 1216/12639]\n",
      "loss: 0.000016  [ 2432/12639]\n",
      "loss: 0.000053  [ 3648/12639]\n",
      "loss: 0.000029  [ 4864/12639]\n",
      "loss: 0.000044  [ 6080/12639]\n",
      "loss: 0.000024  [ 7296/12639]\n",
      "loss: 0.000022  [ 8512/12639]\n",
      "loss: 0.000044  [ 9728/12639]\n",
      "loss: 0.000016  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.704592 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.000020  [    0/12639]\n",
      "loss: 0.000026  [ 1216/12639]\n",
      "loss: 0.000016  [ 2432/12639]\n",
      "loss: 0.000064  [ 3648/12639]\n",
      "loss: 0.000023  [ 4864/12639]\n",
      "loss: 0.000014  [ 6080/12639]\n",
      "loss: 0.000020  [ 7296/12639]\n",
      "loss: 0.000020  [ 8512/12639]\n",
      "loss: 0.000057  [ 9728/12639]\n",
      "loss: 0.000024  [10944/12639]\n",
      "loss: 0.000072  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.719003 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/12639]\n",
      "loss: 0.000019  [ 1216/12639]\n",
      "loss: 0.000022  [ 2432/12639]\n",
      "loss: 0.000014  [ 3648/12639]\n",
      "loss: 0.000033  [ 4864/12639]\n",
      "loss: 0.000010  [ 6080/12639]\n",
      "loss: 0.000029  [ 7296/12639]\n",
      "loss: 0.000029  [ 8512/12639]\n",
      "loss: 0.000029  [ 9728/12639]\n",
      "loss: 0.000029  [10944/12639]\n",
      "loss: 0.000012  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.731776 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.000038  [    0/12639]\n",
      "loss: 0.000019  [ 1216/12639]\n",
      "loss: 0.000044  [ 2432/12639]\n",
      "loss: 0.000020  [ 3648/12639]\n",
      "loss: 0.000022  [ 4864/12639]\n",
      "loss: 0.000029  [ 6080/12639]\n",
      "loss: 0.000015  [ 7296/12639]\n",
      "loss: 0.000032  [ 8512/12639]\n",
      "loss: 0.000015  [ 9728/12639]\n",
      "loss: 0.000014  [10944/12639]\n",
      "loss: 0.000023  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.743407 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.000044  [    0/12639]\n",
      "loss: 0.000046  [ 1216/12639]\n",
      "loss: 0.000024  [ 2432/12639]\n",
      "loss: 0.000025  [ 3648/12639]\n",
      "loss: 0.000036  [ 4864/12639]\n",
      "loss: 0.000010  [ 6080/12639]\n",
      "loss: 0.000006  [ 7296/12639]\n",
      "loss: 0.000013  [ 8512/12639]\n",
      "loss: 0.000012  [ 9728/12639]\n",
      "loss: 0.000026  [10944/12639]\n",
      "loss: 0.000037  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.754369 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.000018  [    0/12639]\n",
      "loss: 0.000010  [ 1216/12639]\n",
      "loss: 0.000029  [ 2432/12639]\n",
      "loss: 0.000026  [ 3648/12639]\n",
      "loss: 0.000007  [ 4864/12639]\n",
      "loss: 0.000015  [ 6080/12639]\n",
      "loss: 0.000034  [ 7296/12639]\n",
      "loss: 0.000023  [ 8512/12639]\n",
      "loss: 0.000026  [ 9728/12639]\n",
      "loss: 0.000037  [10944/12639]\n",
      "loss: 0.000024  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.764383 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/12639]\n",
      "loss: 0.000018  [ 1216/12639]\n",
      "loss: 0.000006  [ 2432/12639]\n",
      "loss: 0.000015  [ 3648/12639]\n",
      "loss: 0.000012  [ 4864/12639]\n",
      "loss: 0.000013  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000019  [ 8512/12639]\n",
      "loss: 0.000008  [ 9728/12639]\n",
      "loss: 0.000020  [10944/12639]\n",
      "loss: 0.000026  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.774313 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.000016  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000012  [ 2432/12639]\n",
      "loss: 0.000017  [ 3648/12639]\n",
      "loss: 0.000017  [ 4864/12639]\n",
      "loss: 0.000021  [ 6080/12639]\n",
      "loss: 0.000015  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000033  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.783418 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000013  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000017  [ 3648/12639]\n",
      "loss: 0.000021  [ 4864/12639]\n",
      "loss: 0.000017  [ 6080/12639]\n",
      "loss: 0.000022  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000023  [ 9728/12639]\n",
      "loss: 0.000018  [10944/12639]\n",
      "loss: 0.000012  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.792065 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/12639]\n",
      "loss: 0.000008  [ 1216/12639]\n",
      "loss: 0.000020  [ 2432/12639]\n",
      "loss: 0.000036  [ 3648/12639]\n",
      "loss: 0.000015  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000004  [ 7296/12639]\n",
      "loss: 0.000029  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000009  [10944/12639]\n",
      "loss: 0.000008  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.800454 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/12639]\n",
      "loss: 0.000014  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000029  [ 3648/12639]\n",
      "loss: 0.000010  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000043  [ 7296/12639]\n",
      "loss: 0.000019  [ 8512/12639]\n",
      "loss: 0.000011  [ 9728/12639]\n",
      "loss: 0.000010  [10944/12639]\n",
      "loss: 0.000021  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.808497 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/12639]\n",
      "loss: 0.000011  [ 1216/12639]\n",
      "loss: 0.000013  [ 2432/12639]\n",
      "loss: 0.000017  [ 3648/12639]\n",
      "loss: 0.000019  [ 4864/12639]\n",
      "loss: 0.000011  [ 6080/12639]\n",
      "loss: 0.000028  [ 7296/12639]\n",
      "loss: 0.000012  [ 8512/12639]\n",
      "loss: 0.000023  [ 9728/12639]\n",
      "loss: 0.000021  [10944/12639]\n",
      "loss: 0.000023  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.816086 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000021  [ 1216/12639]\n",
      "loss: 0.000025  [ 2432/12639]\n",
      "loss: 0.000007  [ 3648/12639]\n",
      "loss: 0.000007  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000022  [ 7296/12639]\n",
      "loss: 0.000018  [ 8512/12639]\n",
      "loss: 0.000027  [ 9728/12639]\n",
      "loss: 0.000020  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.823490 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/12639]\n",
      "loss: 0.000011  [ 1216/12639]\n",
      "loss: 0.000014  [ 2432/12639]\n",
      "loss: 0.000025  [ 3648/12639]\n",
      "loss: 0.000039  [ 4864/12639]\n",
      "loss: 0.000017  [ 6080/12639]\n",
      "loss: 0.000037  [ 7296/12639]\n",
      "loss: 0.000010  [ 8512/12639]\n",
      "loss: 0.000008  [ 9728/12639]\n",
      "loss: 0.000007  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.830566 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000008  [ 2432/12639]\n",
      "loss: 0.000011  [ 3648/12639]\n",
      "loss: 0.000022  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000018  [ 9728/12639]\n",
      "loss: 0.000001  [10944/12639]\n",
      "loss: 0.000009  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.837453 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000011  [ 2432/12639]\n",
      "loss: 0.000016  [ 3648/12639]\n",
      "loss: 0.000029  [ 4864/12639]\n",
      "loss: 0.000011  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000006  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000007  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.844173 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.000028  [    0/12639]\n",
      "loss: 0.000010  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000013  [ 4864/12639]\n",
      "loss: 0.000011  [ 6080/12639]\n",
      "loss: 0.000007  [ 7296/12639]\n",
      "loss: 0.000013  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000011  [10944/12639]\n",
      "loss: 0.000013  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.850490 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/12639]\n",
      "loss: 0.000014  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000012  [ 3648/12639]\n",
      "loss: 0.000012  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000005  [ 7296/12639]\n",
      "loss: 0.000002  [ 8512/12639]\n",
      "loss: 0.000011  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000009  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.856335 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.000012  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000012  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000002  [ 4864/12639]\n",
      "loss: 0.000008  [ 6080/12639]\n",
      "loss: 0.000013  [ 7296/12639]\n",
      "loss: 0.000037  [ 8512/12639]\n",
      "loss: 0.000012  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000015  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.862454 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/12639]\n",
      "loss: 0.000048  [ 1216/12639]\n",
      "loss: 0.000025  [ 2432/12639]\n",
      "loss: 0.000013  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000013  [ 8512/12639]\n",
      "loss: 0.000003  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000005  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.868275 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000021  [ 2432/12639]\n",
      "loss: 0.000004  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000025  [ 6080/12639]\n",
      "loss: 0.000007  [ 7296/12639]\n",
      "loss: 0.000020  [ 8512/12639]\n",
      "loss: 0.000009  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000010  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.873677 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000023  [    0/12639]\n",
      "loss: 0.000011  [ 1216/12639]\n",
      "loss: 0.000010  [ 2432/12639]\n",
      "loss: 0.000009  [ 3648/12639]\n",
      "loss: 0.000019  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.879189 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.000007  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000014  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000012  [ 4864/12639]\n",
      "loss: 0.000017  [ 6080/12639]\n",
      "loss: 0.000012  [ 7296/12639]\n",
      "loss: 0.000010  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000011  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.884390 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.000010  [    0/12639]\n",
      "loss: 0.000012  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000009  [ 3648/12639]\n",
      "loss: 0.000012  [ 4864/12639]\n",
      "loss: 0.000004  [ 6080/12639]\n",
      "loss: 0.000004  [ 7296/12639]\n",
      "loss: 0.000008  [ 8512/12639]\n",
      "loss: 0.000018  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000022  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.889428 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/12639]\n",
      "loss: 0.000013  [ 1216/12639]\n",
      "loss: 0.000018  [ 2432/12639]\n",
      "loss: 0.000002  [ 3648/12639]\n",
      "loss: 0.000013  [ 4864/12639]\n",
      "loss: 0.000003  [ 6080/12639]\n",
      "loss: 0.000013  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000007  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000011  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.894321 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000012  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000011  [ 3648/12639]\n",
      "loss: 0.000009  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000007  [ 7296/12639]\n",
      "loss: 0.000010  [ 8512/12639]\n",
      "loss: 0.000003  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.899143 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.000014  [    0/12639]\n",
      "loss: 0.000005  [ 1216/12639]\n",
      "loss: 0.000009  [ 2432/12639]\n",
      "loss: 0.000007  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000011  [ 8512/12639]\n",
      "loss: 0.000006  [ 9728/12639]\n",
      "loss: 0.000010  [10944/12639]\n",
      "loss: 0.000015  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.903793 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000007  [ 3648/12639]\n",
      "loss: 0.000003  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000003  [ 8512/12639]\n",
      "loss: 0.000006  [ 9728/12639]\n",
      "loss: 0.000015  [10944/12639]\n",
      "loss: 0.000004  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.908392 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000015  [ 1216/12639]\n",
      "loss: 0.000006  [ 2432/12639]\n",
      "loss: 0.000013  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000012  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000008  [10944/12639]\n",
      "loss: 0.000009  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.912863 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000018  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000018  [ 4864/12639]\n",
      "loss: 0.000004  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000011  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000013  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.917107 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/12639]\n",
      "loss: 0.000009  [ 1216/12639]\n",
      "loss: 0.000008  [ 2432/12639]\n",
      "loss: 0.000016  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000004  [ 6080/12639]\n",
      "loss: 0.000010  [ 7296/12639]\n",
      "loss: 0.000011  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000019  [10944/12639]\n",
      "loss: 0.000011  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.921566 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000014  [    0/12639]\n",
      "loss: 0.000008  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000009  [ 9728/12639]\n",
      "loss: 0.000010  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.925733 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000005  [ 1216/12639]\n",
      "loss: 0.000002  [ 2432/12639]\n",
      "loss: 0.000013  [ 3648/12639]\n",
      "loss: 0.000011  [ 4864/12639]\n",
      "loss: 0.000008  [ 6080/12639]\n",
      "loss: 0.000006  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000019  [ 9728/12639]\n",
      "loss: 0.000023  [10944/12639]\n",
      "loss: 0.000009  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.929788 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000005  [ 1216/12639]\n",
      "loss: 0.000004  [ 2432/12639]\n",
      "loss: 0.000004  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000001  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000008  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.933630 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/12639]\n",
      "loss: 0.000012  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000012  [ 3648/12639]\n",
      "loss: 0.000009  [ 4864/12639]\n",
      "loss: 0.000008  [ 6080/12639]\n",
      "loss: 0.000010  [ 7296/12639]\n",
      "loss: 0.000013  [ 8512/12639]\n",
      "loss: 0.000013  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 2.937626 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/12639]\n",
      "loss: 0.000010  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000011  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000007  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000016  [ 8512/12639]\n",
      "loss: 0.000009  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 2.941474 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000002  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000026  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000001  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000002  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.945366 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000008  [ 2432/12639]\n",
      "loss: 0.000012  [ 3648/12639]\n",
      "loss: 0.000009  [ 4864/12639]\n",
      "loss: 0.000004  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000010  [10944/12639]\n",
      "loss: 0.000004  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.949096 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000004  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000008  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000003  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000013  [10944/12639]\n",
      "loss: 0.000002  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.952670 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.000011  [    0/12639]\n",
      "loss: 0.000008  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000003  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000005  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000015  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000007  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.956106 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000022  [    0/12639]\n",
      "loss: 0.000002  [ 1216/12639]\n",
      "loss: 0.000006  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000003  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000003  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000014  [10944/12639]\n",
      "loss: 0.000004  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.959645 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000001  [ 2432/12639]\n",
      "loss: 0.000003  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000010  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000007  [ 9728/12639]\n",
      "loss: 0.000008  [10944/12639]\n",
      "loss: 0.000007  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.962961 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/12639]\n",
      "loss: 0.000005  [ 1216/12639]\n",
      "loss: 0.000009  [ 2432/12639]\n",
      "loss: 0.000003  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000003  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000001  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.966293 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000005  [ 1216/12639]\n",
      "loss: 0.000001  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000004  [ 7296/12639]\n",
      "loss: 0.000003  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000001  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.969737 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000009  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000007  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000003  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.972932 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/12639]\n",
      "loss: 0.000012  [ 1216/12639]\n",
      "loss: 0.000001  [ 2432/12639]\n",
      "loss: 0.000009  [ 3648/12639]\n",
      "loss: 0.000015  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000004  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000012  [ 9728/12639]\n",
      "loss: 0.000003  [10944/12639]\n",
      "loss: 0.000005  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.976163 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000004  [ 2432/12639]\n",
      "loss: 0.000008  [ 3648/12639]\n",
      "loss: 0.000017  [ 4864/12639]\n",
      "loss: 0.000003  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000006  [ 8512/12639]\n",
      "loss: 0.000007  [ 9728/12639]\n",
      "loss: 0.000012  [10944/12639]\n",
      "loss: 0.000015  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.979303 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000007  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000004  [ 3648/12639]\n",
      "loss: 0.000012  [ 4864/12639]\n",
      "loss: 0.000003  [ 6080/12639]\n",
      "loss: 0.000003  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000001  [10944/12639]\n",
      "loss: 0.000002  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.982382 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/12639]\n",
      "loss: 0.000008  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000006  [ 3648/12639]\n",
      "loss: 0.000015  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000008  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000005  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.985452 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/12639]\n",
      "loss: 0.000008  [ 1216/12639]\n",
      "loss: 0.000006  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000011  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000005  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.988463 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000001  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000004  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000003  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.991442 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000004  [ 2432/12639]\n",
      "loss: 0.000010  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000009  [ 6080/12639]\n",
      "loss: 0.000003  [ 7296/12639]\n",
      "loss: 0.000010  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000012  [10944/12639]\n",
      "loss: 0.000010  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.994445 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000002  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000004  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000005  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 2.997315 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000001  [    0/12639]\n",
      "loss: 0.000002  [ 1216/12639]\n",
      "loss: 0.000006  [ 2432/12639]\n",
      "loss: 0.000007  [ 3648/12639]\n",
      "loss: 0.000007  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000007  [ 7296/12639]\n",
      "loss: 0.000007  [ 8512/12639]\n",
      "loss: 0.000007  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 3.000112 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000011  [ 2432/12639]\n",
      "loss: 0.000001  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000003  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000014  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000005  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 3.002982 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000005  [    0/12639]\n",
      "loss: 0.000002  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000004  [ 3648/12639]\n",
      "loss: 0.000003  [ 4864/12639]\n",
      "loss: 0.000008  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000008  [ 8512/12639]\n",
      "loss: 0.000003  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 68.0%, Avg loss: 3.005643 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000004  [    0/12639]\n",
      "loss: 0.000004  [ 1216/12639]\n",
      "loss: 0.000004  [ 2432/12639]\n",
      "loss: 0.000003  [ 3648/12639]\n",
      "loss: 0.000004  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000009  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000007  [ 9728/12639]\n",
      "loss: 0.000006  [10944/12639]\n",
      "loss: 0.000006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.008432 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000002  [    0/12639]\n",
      "loss: 0.000004  [ 1216/12639]\n",
      "loss: 0.000005  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000007  [ 4864/12639]\n",
      "loss: 0.000001  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000001  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.011088 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000015  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000002  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000002  [ 6080/12639]\n",
      "loss: 0.000002  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000005  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000001  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.013780 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/12639]\n",
      "loss: 0.000004  [ 1216/12639]\n",
      "loss: 0.000003  [ 2432/12639]\n",
      "loss: 0.000005  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000003  [ 6080/12639]\n",
      "loss: 0.000008  [ 7296/12639]\n",
      "loss: 0.000000  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000003  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.016388 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.000008  [    0/12639]\n",
      "loss: 0.000002  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000004  [ 3648/12639]\n",
      "loss: 0.000008  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000001  [ 8512/12639]\n",
      "loss: 0.000006  [ 9728/12639]\n",
      "loss: 0.000001  [10944/12639]\n",
      "loss: 0.000009  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.018898 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000002  [ 2432/12639]\n",
      "loss: 0.000001  [ 3648/12639]\n",
      "loss: 0.000006  [ 4864/12639]\n",
      "loss: 0.000002  [ 6080/12639]\n",
      "loss: 0.000005  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000001  [ 9728/12639]\n",
      "loss: 0.000003  [10944/12639]\n",
      "loss: 0.000011  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.021442 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000006  [    0/12639]\n",
      "loss: 0.000006  [ 1216/12639]\n",
      "loss: 0.000015  [ 2432/12639]\n",
      "loss: 0.000000  [ 3648/12639]\n",
      "loss: 0.000002  [ 4864/12639]\n",
      "loss: 0.000006  [ 6080/12639]\n",
      "loss: 0.000007  [ 7296/12639]\n",
      "loss: 0.000005  [ 8512/12639]\n",
      "loss: 0.000002  [ 9728/12639]\n",
      "loss: 0.000004  [10944/12639]\n",
      "loss: 0.000001  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.023964 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.000003  [    0/12639]\n",
      "loss: 0.000003  [ 1216/12639]\n",
      "loss: 0.000007  [ 2432/12639]\n",
      "loss: 0.000003  [ 3648/12639]\n",
      "loss: 0.000005  [ 4864/12639]\n",
      "loss: 0.000005  [ 6080/12639]\n",
      "loss: 0.000001  [ 7296/12639]\n",
      "loss: 0.000004  [ 8512/12639]\n",
      "loss: 0.000004  [ 9728/12639]\n",
      "loss: 0.000002  [10944/12639]\n",
      "loss: 0.000007  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 3.026493 \n",
      "\n",
      "Done!\n",
      "Writing 'out_normal.stdout' (str) to file '../result/Butterfly_original.txt'.\n"
     ]
    }
   ],
   "source": [
    "out_normal()\n",
    "%store out_normal.stdout >../result/Butterfly_original.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out_dwt\n",
    "run(train_loader_dwt, val_loader_dwt, net_dwt, loss_fn, optimizer_dwt, device, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.401084  [    0/12639]\n",
      "loss: 4.604541  [ 1216/12639]\n",
      "loss: 4.488633  [ 2432/12639]\n",
      "loss: 4.548667  [ 3648/12639]\n",
      "loss: 4.510901  [ 4864/12639]\n",
      "loss: 4.196357  [ 6080/12639]\n",
      "loss: 4.383579  [ 7296/12639]\n",
      "loss: 4.390108  [ 8512/12639]\n",
      "loss: 4.322053  [ 9728/12639]\n",
      "loss: 4.167436  [10944/12639]\n",
      "loss: 4.008914  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 11.0%, Avg loss: 3.922929 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.768031  [    0/12639]\n",
      "loss: 3.898369  [ 1216/12639]\n",
      "loss: 3.166620  [ 2432/12639]\n",
      "loss: 3.878421  [ 3648/12639]\n",
      "loss: 3.667003  [ 4864/12639]\n",
      "loss: 2.970996  [ 6080/12639]\n",
      "loss: 3.628529  [ 7296/12639]\n",
      "loss: 3.186264  [ 8512/12639]\n",
      "loss: 3.314933  [ 9728/12639]\n",
      "loss: 3.019771  [10944/12639]\n",
      "loss: 2.962016  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 24.2%, Avg loss: 3.191054 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.846654  [    0/12639]\n",
      "loss: 2.912115  [ 1216/12639]\n",
      "loss: 2.893925  [ 2432/12639]\n",
      "loss: 2.770036  [ 3648/12639]\n",
      "loss: 2.820946  [ 4864/12639]\n",
      "loss: 2.804861  [ 6080/12639]\n",
      "loss: 2.609516  [ 7296/12639]\n",
      "loss: 2.534550  [ 8512/12639]\n",
      "loss: 3.135414  [ 9728/12639]\n",
      "loss: 2.898768  [10944/12639]\n",
      "loss: 3.281373  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 30.4%, Avg loss: 3.048846 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 3.155168  [    0/12639]\n",
      "loss: 2.140822  [ 1216/12639]\n",
      "loss: 2.469320  [ 2432/12639]\n",
      "loss: 3.012361  [ 3648/12639]\n",
      "loss: 2.917507  [ 4864/12639]\n",
      "loss: 2.750925  [ 6080/12639]\n",
      "loss: 2.616286  [ 7296/12639]\n",
      "loss: 2.459670  [ 8512/12639]\n",
      "loss: 2.610531  [ 9728/12639]\n",
      "loss: 2.962008  [10944/12639]\n",
      "loss: 2.456030  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 2.692887 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.682950  [    0/12639]\n",
      "loss: 2.235206  [ 1216/12639]\n",
      "loss: 2.141397  [ 2432/12639]\n",
      "loss: 1.769261  [ 3648/12639]\n",
      "loss: 2.247165  [ 4864/12639]\n",
      "loss: 1.471814  [ 6080/12639]\n",
      "loss: 1.879443  [ 7296/12639]\n",
      "loss: 1.931182  [ 8512/12639]\n",
      "loss: 1.803379  [ 9728/12639]\n",
      "loss: 2.045136  [10944/12639]\n",
      "loss: 2.485380  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 2.548732 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.441345  [    0/12639]\n",
      "loss: 1.448548  [ 1216/12639]\n",
      "loss: 1.794686  [ 2432/12639]\n",
      "loss: 1.527209  [ 3648/12639]\n",
      "loss: 1.287739  [ 4864/12639]\n",
      "loss: 2.303921  [ 6080/12639]\n",
      "loss: 1.856536  [ 7296/12639]\n",
      "loss: 2.045567  [ 8512/12639]\n",
      "loss: 1.848523  [ 9728/12639]\n",
      "loss: 1.319324  [10944/12639]\n",
      "loss: 2.236116  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 2.837146 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.998901  [    0/12639]\n",
      "loss: 1.083895  [ 1216/12639]\n",
      "loss: 2.839170  [ 2432/12639]\n",
      "loss: 1.854738  [ 3648/12639]\n",
      "loss: 1.739827  [ 4864/12639]\n",
      "loss: 1.679814  [ 6080/12639]\n",
      "loss: 1.851182  [ 7296/12639]\n",
      "loss: 1.936084  [ 8512/12639]\n",
      "loss: 1.514389  [ 9728/12639]\n",
      "loss: 1.613747  [10944/12639]\n",
      "loss: 1.849658  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 35.0%, Avg loss: 3.535880 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.201517  [    0/12639]\n",
      "loss: 1.578987  [ 1216/12639]\n",
      "loss: 1.335813  [ 2432/12639]\n",
      "loss: 1.094524  [ 3648/12639]\n",
      "loss: 1.287912  [ 4864/12639]\n",
      "loss: 1.971969  [ 6080/12639]\n",
      "loss: 1.621665  [ 7296/12639]\n",
      "loss: 1.690558  [ 8512/12639]\n",
      "loss: 1.868808  [ 9728/12639]\n",
      "loss: 1.417332  [10944/12639]\n",
      "loss: 1.175953  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 31.0%, Avg loss: 4.068871 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.917367  [    0/12639]\n",
      "loss: 1.140887  [ 1216/12639]\n",
      "loss: 2.046214  [ 2432/12639]\n",
      "loss: 1.218246  [ 3648/12639]\n",
      "loss: 1.304388  [ 4864/12639]\n",
      "loss: 1.605645  [ 6080/12639]\n",
      "loss: 2.267819  [ 7296/12639]\n",
      "loss: 2.057006  [ 8512/12639]\n",
      "loss: 1.468225  [ 9728/12639]\n",
      "loss: 2.184840  [10944/12639]\n",
      "loss: 2.116530  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 30.2%, Avg loss: 3.519342 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.420367  [    0/12639]\n",
      "loss: 0.790234  [ 1216/12639]\n",
      "loss: 2.106307  [ 2432/12639]\n",
      "loss: 1.874173  [ 3648/12639]\n",
      "loss: 1.188474  [ 4864/12639]\n",
      "loss: 1.348434  [ 6080/12639]\n",
      "loss: 1.806528  [ 7296/12639]\n",
      "loss: 1.622606  [ 8512/12639]\n",
      "loss: 1.342712  [ 9728/12639]\n",
      "loss: 1.802004  [10944/12639]\n",
      "loss: 1.826262  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 31.2%, Avg loss: 3.943264 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.050673  [    0/12639]\n",
      "loss: 1.239382  [ 1216/12639]\n",
      "loss: 0.997100  [ 2432/12639]\n",
      "loss: 1.068995  [ 3648/12639]\n",
      "loss: 2.250527  [ 4864/12639]\n",
      "loss: 1.920415  [ 6080/12639]\n",
      "loss: 4.530186  [ 7296/12639]\n",
      "loss: 4.278193  [ 8512/12639]\n",
      "loss: 2.533714  [ 9728/12639]\n",
      "loss: 2.443352  [10944/12639]\n",
      "loss: 3.478671  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 27.6%, Avg loss: 4.052610 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.831014  [    0/12639]\n",
      "loss: 1.750362  [ 1216/12639]\n",
      "loss: 1.839323  [ 2432/12639]\n",
      "loss: 2.034989  [ 3648/12639]\n",
      "loss: 2.113453  [ 4864/12639]\n",
      "loss: 1.783933  [ 6080/12639]\n",
      "loss: 2.406748  [ 7296/12639]\n",
      "loss: 3.529696  [ 8512/12639]\n",
      "loss: 2.147692  [ 9728/12639]\n",
      "loss: 1.950516  [10944/12639]\n",
      "loss: 2.000488  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 4.637325 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.866396  [    0/12639]\n",
      "loss: 1.402066  [ 1216/12639]\n",
      "loss: 2.801815  [ 2432/12639]\n",
      "loss: 2.204073  [ 3648/12639]\n",
      "loss: 1.593539  [ 4864/12639]\n",
      "loss: 2.046175  [ 6080/12639]\n",
      "loss: 1.912946  [ 7296/12639]\n",
      "loss: 1.343461  [ 8512/12639]\n",
      "loss: 1.529358  [ 9728/12639]\n",
      "loss: 2.714246  [10944/12639]\n",
      "loss: 2.401432  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 30.2%, Avg loss: 3.682069 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.262385  [    0/12639]\n",
      "loss: 1.478956  [ 1216/12639]\n",
      "loss: 1.947532  [ 2432/12639]\n",
      "loss: 1.833623  [ 3648/12639]\n",
      "loss: 1.636324  [ 4864/12639]\n",
      "loss: 1.432908  [ 6080/12639]\n",
      "loss: 2.418255  [ 7296/12639]\n",
      "loss: 2.412270  [ 8512/12639]\n",
      "loss: 2.104012  [ 9728/12639]\n",
      "loss: 2.279049  [10944/12639]\n",
      "loss: 2.836248  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 22.4%, Avg loss: 4.246512 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.916405  [    0/12639]\n",
      "loss: 1.696872  [ 1216/12639]\n",
      "loss: 1.607972  [ 2432/12639]\n",
      "loss: 1.678750  [ 3648/12639]\n",
      "loss: 1.336503  [ 4864/12639]\n",
      "loss: 1.726038  [ 6080/12639]\n",
      "loss: 1.368030  [ 7296/12639]\n",
      "loss: 3.651133  [ 8512/12639]\n",
      "loss: 1.853930  [ 9728/12639]\n",
      "loss: 2.130938  [10944/12639]\n",
      "loss: 3.111138  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 25.6%, Avg loss: 4.321613 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.519284  [    0/12639]\n",
      "loss: 2.271547  [ 1216/12639]\n",
      "loss: 3.138835  [ 2432/12639]\n",
      "loss: 1.994256  [ 3648/12639]\n",
      "loss: 1.538887  [ 4864/12639]\n",
      "loss: 1.851063  [ 6080/12639]\n",
      "loss: 1.324397  [ 7296/12639]\n",
      "loss: 3.657695  [ 8512/12639]\n",
      "loss: 2.634456  [ 9728/12639]\n",
      "loss: 2.518311  [10944/12639]\n",
      "loss: 1.816982  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 25.4%, Avg loss: 4.631960 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.178317  [    0/12639]\n",
      "loss: 1.280041  [ 1216/12639]\n",
      "loss: 4.057428  [ 2432/12639]\n",
      "loss: 2.732042  [ 3648/12639]\n",
      "loss: 1.760352  [ 4864/12639]\n",
      "loss: 1.693544  [ 6080/12639]\n",
      "loss: 2.756618  [ 7296/12639]\n",
      "loss: 2.960922  [ 8512/12639]\n",
      "loss: 2.292703  [ 9728/12639]\n",
      "loss: 2.728928  [10944/12639]\n",
      "loss: 1.840384  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 27.0%, Avg loss: 4.358657 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.514398  [    0/12639]\n",
      "loss: 1.268235  [ 1216/12639]\n",
      "loss: 1.406626  [ 2432/12639]\n",
      "loss: 3.286505  [ 3648/12639]\n",
      "loss: 4.630856  [ 4864/12639]\n",
      "loss: 4.668440  [ 6080/12639]\n",
      "loss: 4.608452  [ 7296/12639]\n",
      "loss: 4.720284  [ 8512/12639]\n",
      "loss: 4.633766  [ 9728/12639]\n",
      "loss: 4.609986  [10944/12639]\n",
      "loss: 4.629167  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.618244 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 4.599973  [    0/12639]\n",
      "loss: 4.564957  [ 1216/12639]\n",
      "loss: 4.622509  [ 2432/12639]\n",
      "loss: 4.615089  [ 3648/12639]\n",
      "loss: 4.606845  [ 4864/12639]\n",
      "loss: 4.608965  [ 6080/12639]\n",
      "loss: 4.614338  [ 7296/12639]\n",
      "loss: 4.594988  [ 8512/12639]\n",
      "loss: 4.591228  [ 9728/12639]\n",
      "loss: 4.629460  [10944/12639]\n",
      "loss: 4.582713  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.611122 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 4.590903  [    0/12639]\n",
      "loss: 4.606277  [ 1216/12639]\n",
      "loss: 4.623754  [ 2432/12639]\n",
      "loss: 4.603544  [ 3648/12639]\n",
      "loss: 4.612124  [ 4864/12639]\n",
      "loss: 4.623930  [ 6080/12639]\n",
      "loss: 4.643823  [ 7296/12639]\n",
      "loss: 4.609207  [ 8512/12639]\n",
      "loss: 4.631471  [ 9728/12639]\n",
      "loss: 4.591945  [10944/12639]\n",
      "loss: 4.629676  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611808 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 4.623029  [    0/12639]\n",
      "loss: 4.604734  [ 1216/12639]\n",
      "loss: 4.552107  [ 2432/12639]\n",
      "loss: 4.601962  [ 3648/12639]\n",
      "loss: 4.621363  [ 4864/12639]\n",
      "loss: 4.610039  [ 6080/12639]\n",
      "loss: 4.612153  [ 7296/12639]\n",
      "loss: 4.633373  [ 8512/12639]\n",
      "loss: 4.604949  [ 9728/12639]\n",
      "loss: 4.623482  [10944/12639]\n",
      "loss: 4.576181  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.609422 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 4.612261  [    0/12639]\n",
      "loss: 4.627003  [ 1216/12639]\n",
      "loss: 4.607386  [ 2432/12639]\n",
      "loss: 4.607834  [ 3648/12639]\n",
      "loss: 4.615966  [ 4864/12639]\n",
      "loss: 4.601467  [ 6080/12639]\n",
      "loss: 4.649635  [ 7296/12639]\n",
      "loss: 4.595769  [ 8512/12639]\n",
      "loss: 4.600163  [ 9728/12639]\n",
      "loss: 4.580687  [10944/12639]\n",
      "loss: 4.601888  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.617922 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 4.607441  [    0/12639]\n",
      "loss: 4.578368  [ 1216/12639]\n",
      "loss: 4.604732  [ 2432/12639]\n",
      "loss: 4.623569  [ 3648/12639]\n",
      "loss: 4.596858  [ 4864/12639]\n",
      "loss: 4.599320  [ 6080/12639]\n",
      "loss: 4.563671  [ 7296/12639]\n",
      "loss: 4.590234  [ 8512/12639]\n",
      "loss: 4.626194  [ 9728/12639]\n",
      "loss: 4.634562  [10944/12639]\n",
      "loss: 4.608539  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.609213 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 4.553246  [    0/12639]\n",
      "loss: 4.592622  [ 1216/12639]\n",
      "loss: 4.555748  [ 2432/12639]\n",
      "loss: 4.617867  [ 3648/12639]\n",
      "loss: 4.578794  [ 4864/12639]\n",
      "loss: 4.572012  [ 6080/12639]\n",
      "loss: 4.611792  [ 7296/12639]\n",
      "loss: 4.528126  [ 8512/12639]\n",
      "loss: 4.585721  [ 9728/12639]\n",
      "loss: 4.615763  [10944/12639]\n",
      "loss: 4.657987  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.612967 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 4.604999  [    0/12639]\n",
      "loss: 4.596950  [ 1216/12639]\n",
      "loss: 4.587713  [ 2432/12639]\n",
      "loss: 4.579996  [ 3648/12639]\n",
      "loss: 4.603617  [ 4864/12639]\n",
      "loss: 4.575505  [ 6080/12639]\n",
      "loss: 4.572517  [ 7296/12639]\n",
      "loss: 4.608088  [ 8512/12639]\n",
      "loss: 4.596606  [ 9728/12639]\n",
      "loss: 4.580812  [10944/12639]\n",
      "loss: 4.585605  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611829 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 4.602276  [    0/12639]\n",
      "loss: 4.596151  [ 1216/12639]\n",
      "loss: 4.605142  [ 2432/12639]\n",
      "loss: 4.608839  [ 3648/12639]\n",
      "loss: 4.613922  [ 4864/12639]\n",
      "loss: 4.609084  [ 6080/12639]\n",
      "loss: 4.603726  [ 7296/12639]\n",
      "loss: 4.574907  [ 8512/12639]\n",
      "loss: 4.601176  [ 9728/12639]\n",
      "loss: 4.611402  [10944/12639]\n",
      "loss: 4.608160  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611675 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 4.577730  [    0/12639]\n",
      "loss: 4.578176  [ 1216/12639]\n",
      "loss: 4.573958  [ 2432/12639]\n",
      "loss: 4.610190  [ 3648/12639]\n",
      "loss: 4.605798  [ 4864/12639]\n",
      "loss: 4.615154  [ 6080/12639]\n",
      "loss: 4.595114  [ 7296/12639]\n",
      "loss: 4.596235  [ 8512/12639]\n",
      "loss: 4.615109  [ 9728/12639]\n",
      "loss: 4.595305  [10944/12639]\n",
      "loss: 4.598874  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.615291 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 4.611750  [    0/12639]\n",
      "loss: 4.592673  [ 1216/12639]\n",
      "loss: 4.606398  [ 2432/12639]\n",
      "loss: 4.597095  [ 3648/12639]\n",
      "loss: 4.592736  [ 4864/12639]\n",
      "loss: 4.603833  [ 6080/12639]\n",
      "loss: 4.597977  [ 7296/12639]\n",
      "loss: 4.605102  [ 8512/12639]\n",
      "loss: 4.591568  [ 9728/12639]\n",
      "loss: 4.579023  [10944/12639]\n",
      "loss: 4.592024  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.613305 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 4.597396  [    0/12639]\n",
      "loss: 4.606701  [ 1216/12639]\n",
      "loss: 4.600361  [ 2432/12639]\n",
      "loss: 4.593291  [ 3648/12639]\n",
      "loss: 4.678726  [ 4864/12639]\n",
      "loss: 4.573162  [ 6080/12639]\n",
      "loss: 4.592317  [ 7296/12639]\n",
      "loss: 4.602689  [ 8512/12639]\n",
      "loss: 4.592873  [ 9728/12639]\n",
      "loss: 4.647529  [10944/12639]\n",
      "loss: 4.604638  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611157 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 4.627422  [    0/12639]\n",
      "loss: 4.578036  [ 1216/12639]\n",
      "loss: 4.565824  [ 2432/12639]\n",
      "loss: 4.544470  [ 3648/12639]\n",
      "loss: 4.610620  [ 4864/12639]\n",
      "loss: 4.599622  [ 6080/12639]\n",
      "loss: 4.608639  [ 7296/12639]\n",
      "loss: 4.573414  [ 8512/12639]\n",
      "loss: 4.627247  [ 9728/12639]\n",
      "loss: 4.609272  [10944/12639]\n",
      "loss: 4.597476  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.627008 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 4.590624  [    0/12639]\n",
      "loss: 4.577332  [ 1216/12639]\n",
      "loss: 4.586535  [ 2432/12639]\n",
      "loss: 4.596885  [ 3648/12639]\n",
      "loss: 4.594452  [ 4864/12639]\n",
      "loss: 4.596162  [ 6080/12639]\n",
      "loss: 4.580964  [ 7296/12639]\n",
      "loss: 4.614753  [ 8512/12639]\n",
      "loss: 4.594250  [ 9728/12639]\n",
      "loss: 4.539658  [10944/12639]\n",
      "loss: 4.636059  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.630031 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 4.605824  [    0/12639]\n",
      "loss: 4.578778  [ 1216/12639]\n",
      "loss: 4.618525  [ 2432/12639]\n",
      "loss: 4.603340  [ 3648/12639]\n",
      "loss: 4.587449  [ 4864/12639]\n",
      "loss: 4.594708  [ 6080/12639]\n",
      "loss: 4.535700  [ 7296/12639]\n",
      "loss: 4.697855  [ 8512/12639]\n",
      "loss: 4.623875  [ 9728/12639]\n",
      "loss: 4.597292  [10944/12639]\n",
      "loss: 4.533160  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.616752 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 4.611251  [    0/12639]\n",
      "loss: 4.624291  [ 1216/12639]\n",
      "loss: 4.622920  [ 2432/12639]\n",
      "loss: 4.538755  [ 3648/12639]\n",
      "loss: 4.572051  [ 4864/12639]\n",
      "loss: 4.601694  [ 6080/12639]\n",
      "loss: 4.623642  [ 7296/12639]\n",
      "loss: 4.627538  [ 8512/12639]\n",
      "loss: 4.542440  [ 9728/12639]\n",
      "loss: 4.588027  [10944/12639]\n",
      "loss: 4.580827  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.622890 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 4.608250  [    0/12639]\n",
      "loss: 4.617301  [ 1216/12639]\n",
      "loss: 4.570365  [ 2432/12639]\n",
      "loss: 4.608360  [ 3648/12639]\n",
      "loss: 4.484151  [ 4864/12639]\n",
      "loss: 4.586880  [ 6080/12639]\n",
      "loss: 4.610510  [ 7296/12639]\n",
      "loss: 4.596457  [ 8512/12639]\n",
      "loss: 4.608201  [ 9728/12639]\n",
      "loss: 4.649235  [10944/12639]\n",
      "loss: 4.477456  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611101 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 4.585850  [    0/12639]\n",
      "loss: 4.585144  [ 1216/12639]\n",
      "loss: 4.631892  [ 2432/12639]\n",
      "loss: 4.628823  [ 3648/12639]\n",
      "loss: 4.594625  [ 4864/12639]\n",
      "loss: 4.595432  [ 6080/12639]\n",
      "loss: 4.598118  [ 7296/12639]\n",
      "loss: 4.602781  [ 8512/12639]\n",
      "loss: 4.522339  [ 9728/12639]\n",
      "loss: 4.566526  [10944/12639]\n",
      "loss: 4.592407  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.608395 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 4.595911  [    0/12639]\n",
      "loss: 4.531942  [ 1216/12639]\n",
      "loss: 4.608479  [ 2432/12639]\n",
      "loss: 4.549304  [ 3648/12639]\n",
      "loss: 4.510387  [ 4864/12639]\n",
      "loss: 4.588242  [ 6080/12639]\n",
      "loss: 4.611329  [ 7296/12639]\n",
      "loss: 4.580506  [ 8512/12639]\n",
      "loss: 4.614543  [ 9728/12639]\n",
      "loss: 4.580393  [10944/12639]\n",
      "loss: 4.549898  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.610537 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 4.595259  [    0/12639]\n",
      "loss: 4.579538  [ 1216/12639]\n",
      "loss: 4.613244  [ 2432/12639]\n",
      "loss: 4.598218  [ 3648/12639]\n",
      "loss: 4.522700  [ 4864/12639]\n",
      "loss: 4.557061  [ 6080/12639]\n",
      "loss: 4.604049  [ 7296/12639]\n",
      "loss: 4.570770  [ 8512/12639]\n",
      "loss: 4.542391  [ 9728/12639]\n",
      "loss: 4.599099  [10944/12639]\n",
      "loss: 4.560650  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.631505 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 4.612997  [    0/12639]\n",
      "loss: 4.608904  [ 1216/12639]\n",
      "loss: 4.598389  [ 2432/12639]\n",
      "loss: 4.601227  [ 3648/12639]\n",
      "loss: 4.608629  [ 4864/12639]\n",
      "loss: 4.608337  [ 6080/12639]\n",
      "loss: 4.591928  [ 7296/12639]\n",
      "loss: 4.583076  [ 8512/12639]\n",
      "loss: 4.591645  [ 9728/12639]\n",
      "loss: 4.518610  [10944/12639]\n",
      "loss: 4.520006  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.624365 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 4.577677  [    0/12639]\n",
      "loss: 4.587888  [ 1216/12639]\n",
      "loss: 4.513252  [ 2432/12639]\n",
      "loss: 4.591053  [ 3648/12639]\n",
      "loss: 4.600033  [ 4864/12639]\n",
      "loss: 4.495539  [ 6080/12639]\n",
      "loss: 4.623703  [ 7296/12639]\n",
      "loss: 4.609128  [ 8512/12639]\n",
      "loss: 4.456510  [ 9728/12639]\n",
      "loss: 4.545953  [10944/12639]\n",
      "loss: 4.723529  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.617006 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 4.532886  [    0/12639]\n",
      "loss: 4.524413  [ 1216/12639]\n",
      "loss: 4.494956  [ 2432/12639]\n",
      "loss: 4.581075  [ 3648/12639]\n",
      "loss: 4.584753  [ 4864/12639]\n",
      "loss: 4.601417  [ 6080/12639]\n",
      "loss: 4.596295  [ 7296/12639]\n",
      "loss: 4.630316  [ 8512/12639]\n",
      "loss: 4.608874  [ 9728/12639]\n",
      "loss: 4.585250  [10944/12639]\n",
      "loss: 4.640695  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.630247 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 4.551976  [    0/12639]\n",
      "loss: 4.514550  [ 1216/12639]\n",
      "loss: 4.600173  [ 2432/12639]\n",
      "loss: 4.600886  [ 3648/12639]\n",
      "loss: 4.620060  [ 4864/12639]\n",
      "loss: 4.583087  [ 6080/12639]\n",
      "loss: 4.587459  [ 7296/12639]\n",
      "loss: 4.503809  [ 8512/12639]\n",
      "loss: 4.600166  [ 9728/12639]\n",
      "loss: 4.565708  [10944/12639]\n",
      "loss: 4.478761  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.618044 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 4.586518  [    0/12639]\n",
      "loss: 4.597533  [ 1216/12639]\n",
      "loss: 4.514577  [ 2432/12639]\n",
      "loss: 4.599985  [ 3648/12639]\n",
      "loss: 4.585293  [ 4864/12639]\n",
      "loss: 4.582017  [ 6080/12639]\n",
      "loss: 4.557166  [ 7296/12639]\n",
      "loss: 4.508752  [ 8512/12639]\n",
      "loss: 4.591224  [ 9728/12639]\n",
      "loss: 4.592477  [10944/12639]\n",
      "loss: 4.618911  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.635641 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 4.593997  [    0/12639]\n",
      "loss: 4.595209  [ 1216/12639]\n",
      "loss: 4.538882  [ 2432/12639]\n",
      "loss: 4.591753  [ 3648/12639]\n",
      "loss: 4.609133  [ 4864/12639]\n",
      "loss: 4.431575  [ 6080/12639]\n",
      "loss: 4.465926  [ 7296/12639]\n",
      "loss: 4.556346  [ 8512/12639]\n",
      "loss: 4.525873  [ 9728/12639]\n",
      "loss: 4.608929  [10944/12639]\n",
      "loss: 4.606002  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.616027 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 4.580834  [    0/12639]\n",
      "loss: 4.605471  [ 1216/12639]\n",
      "loss: 4.493831  [ 2432/12639]\n",
      "loss: 4.538807  [ 3648/12639]\n",
      "loss: 4.607448  [ 4864/12639]\n",
      "loss: 4.851998  [ 6080/12639]\n",
      "loss: 4.530768  [ 7296/12639]\n",
      "loss: 4.593503  [ 8512/12639]\n",
      "loss: 4.501753  [ 9728/12639]\n",
      "loss: 4.602953  [10944/12639]\n",
      "loss: 4.621729  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.621724 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 4.442854  [    0/12639]\n",
      "loss: 4.390083  [ 1216/12639]\n",
      "loss: 4.602269  [ 2432/12639]\n",
      "loss: 4.509682  [ 3648/12639]\n",
      "loss: 4.596518  [ 4864/12639]\n",
      "loss: 4.622056  [ 6080/12639]\n",
      "loss: 4.563358  [ 7296/12639]\n",
      "loss: 4.589682  [ 8512/12639]\n",
      "loss: 4.547310  [ 9728/12639]\n",
      "loss: 4.602485  [10944/12639]\n",
      "loss: 4.648013  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.615921 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 4.516056  [    0/12639]\n",
      "loss: 4.586344  [ 1216/12639]\n",
      "loss: 4.558228  [ 2432/12639]\n",
      "loss: 4.562727  [ 3648/12639]\n",
      "loss: 4.533355  [ 4864/12639]\n",
      "loss: 4.590867  [ 6080/12639]\n",
      "loss: 4.602015  [ 7296/12639]\n",
      "loss: 4.591764  [ 8512/12639]\n",
      "loss: 4.626532  [ 9728/12639]\n",
      "loss: 4.597128  [10944/12639]\n",
      "loss: 4.584292  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.614557 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 4.464468  [    0/12639]\n",
      "loss: 4.545404  [ 1216/12639]\n",
      "loss: 4.528969  [ 2432/12639]\n",
      "loss: 4.620360  [ 3648/12639]\n",
      "loss: 4.530684  [ 4864/12639]\n",
      "loss: 4.599846  [ 6080/12639]\n",
      "loss: 4.607397  [ 7296/12639]\n",
      "loss: 4.604622  [ 8512/12639]\n",
      "loss: 4.594137  [ 9728/12639]\n",
      "loss: 4.540744  [10944/12639]\n",
      "loss: 4.501224  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.616496 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 4.616881  [    0/12639]\n",
      "loss: 4.529837  [ 1216/12639]\n",
      "loss: 4.583331  [ 2432/12639]\n",
      "loss: 4.588813  [ 3648/12639]\n",
      "loss: 4.607767  [ 4864/12639]\n",
      "loss: 4.516652  [ 6080/12639]\n",
      "loss: 4.626710  [ 7296/12639]\n",
      "loss: 4.577024  [ 8512/12639]\n",
      "loss: 4.496124  [ 9728/12639]\n",
      "loss: 4.612506  [10944/12639]\n",
      "loss: 4.511515  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.623621 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 4.519647  [    0/12639]\n",
      "loss: 4.581528  [ 1216/12639]\n",
      "loss: 4.582600  [ 2432/12639]\n",
      "loss: 4.493967  [ 3648/12639]\n",
      "loss: 4.507277  [ 4864/12639]\n",
      "loss: 4.620756  [ 6080/12639]\n",
      "loss: 4.612267  [ 7296/12639]\n",
      "loss: 4.365661  [ 8512/12639]\n",
      "loss: 4.463319  [ 9728/12639]\n",
      "loss: 4.541790  [10944/12639]\n",
      "loss: 4.510898  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.622912 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 4.474751  [    0/12639]\n",
      "loss: 4.591606  [ 1216/12639]\n",
      "loss: 4.596477  [ 2432/12639]\n",
      "loss: 4.589068  [ 3648/12639]\n",
      "loss: 4.526372  [ 4864/12639]\n",
      "loss: 4.530279  [ 6080/12639]\n",
      "loss: 4.449722  [ 7296/12639]\n",
      "loss: 4.597188  [ 8512/12639]\n",
      "loss: 4.526530  [ 9728/12639]\n",
      "loss: 4.593008  [10944/12639]\n",
      "loss: 4.604972  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.632956 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 4.569932  [    0/12639]\n",
      "loss: 4.507977  [ 1216/12639]\n",
      "loss: 4.595198  [ 2432/12639]\n",
      "loss: 4.444320  [ 3648/12639]\n",
      "loss: 4.512897  [ 4864/12639]\n",
      "loss: 4.602485  [ 6080/12639]\n",
      "loss: 4.602612  [ 7296/12639]\n",
      "loss: 4.588385  [ 8512/12639]\n",
      "loss: 4.610495  [ 9728/12639]\n",
      "loss: 4.604531  [10944/12639]\n",
      "loss: 4.563881  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.610221 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 4.601319  [    0/12639]\n",
      "loss: 4.604137  [ 1216/12639]\n",
      "loss: 4.582158  [ 2432/12639]\n",
      "loss: 4.589878  [ 3648/12639]\n",
      "loss: 4.620947  [ 4864/12639]\n",
      "loss: 4.604240  [ 6080/12639]\n",
      "loss: 4.560811  [ 7296/12639]\n",
      "loss: 4.574380  [ 8512/12639]\n",
      "loss: 4.598901  [ 9728/12639]\n",
      "loss: 4.593851  [10944/12639]\n",
      "loss: 4.614367  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.610764 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 4.602281  [    0/12639]\n",
      "loss: 4.578957  [ 1216/12639]\n",
      "loss: 4.606923  [ 2432/12639]\n",
      "loss: 4.596037  [ 3648/12639]\n",
      "loss: 4.600401  [ 4864/12639]\n",
      "loss: 4.591232  [ 6080/12639]\n",
      "loss: 4.582422  [ 7296/12639]\n",
      "loss: 4.637736  [ 8512/12639]\n",
      "loss: 4.609964  [ 9728/12639]\n",
      "loss: 4.645634  [10944/12639]\n",
      "loss: 4.623569  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.613749 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 4.587809  [    0/12639]\n",
      "loss: 4.613699  [ 1216/12639]\n",
      "loss: 4.597677  [ 2432/12639]\n",
      "loss: 4.558496  [ 3648/12639]\n",
      "loss: 4.591702  [ 4864/12639]\n",
      "loss: 4.599689  [ 6080/12639]\n",
      "loss: 4.561847  [ 7296/12639]\n",
      "loss: 4.572017  [ 8512/12639]\n",
      "loss: 4.610858  [ 9728/12639]\n",
      "loss: 4.588355  [10944/12639]\n",
      "loss: 4.554657  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.610989 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 4.593209  [    0/12639]\n",
      "loss: 4.583598  [ 1216/12639]\n",
      "loss: 4.576714  [ 2432/12639]\n",
      "loss: 4.600065  [ 3648/12639]\n",
      "loss: 4.603003  [ 4864/12639]\n",
      "loss: 4.593210  [ 6080/12639]\n",
      "loss: 4.529733  [ 7296/12639]\n",
      "loss: 4.578355  [ 8512/12639]\n",
      "loss: 4.588344  [ 9728/12639]\n",
      "loss: 4.590367  [10944/12639]\n",
      "loss: 4.618872  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.614400 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 4.590179  [    0/12639]\n",
      "loss: 4.585300  [ 1216/12639]\n",
      "loss: 4.631929  [ 2432/12639]\n",
      "loss: 4.585470  [ 3648/12639]\n",
      "loss: 4.609161  [ 4864/12639]\n",
      "loss: 4.485933  [ 6080/12639]\n",
      "loss: 4.533010  [ 7296/12639]\n",
      "loss: 4.612998  [ 8512/12639]\n",
      "loss: 4.524024  [ 9728/12639]\n",
      "loss: 4.600280  [10944/12639]\n",
      "loss: 4.506506  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611274 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 4.595994  [    0/12639]\n",
      "loss: 4.542017  [ 1216/12639]\n",
      "loss: 4.590781  [ 2432/12639]\n",
      "loss: 4.594886  [ 3648/12639]\n",
      "loss: 4.449811  [ 4864/12639]\n",
      "loss: 4.601223  [ 6080/12639]\n",
      "loss: 4.450185  [ 7296/12639]\n",
      "loss: 4.609272  [ 8512/12639]\n",
      "loss: 4.584150  [ 9728/12639]\n",
      "loss: 4.596340  [10944/12639]\n",
      "loss: 4.611482  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.614873 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 4.519018  [    0/12639]\n",
      "loss: 4.611858  [ 1216/12639]\n",
      "loss: 4.551866  [ 2432/12639]\n",
      "loss: 4.537583  [ 3648/12639]\n",
      "loss: 4.599416  [ 4864/12639]\n",
      "loss: 4.512980  [ 6080/12639]\n",
      "loss: 4.538499  [ 7296/12639]\n",
      "loss: 4.606572  [ 8512/12639]\n",
      "loss: 4.605366  [ 9728/12639]\n",
      "loss: 4.613688  [10944/12639]\n",
      "loss: 4.598306  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.631911 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 4.631503  [    0/12639]\n",
      "loss: 4.487078  [ 1216/12639]\n",
      "loss: 4.608609  [ 2432/12639]\n",
      "loss: 4.565913  [ 3648/12639]\n",
      "loss: 4.563672  [ 4864/12639]\n",
      "loss: 4.564778  [ 6080/12639]\n",
      "loss: 4.593956  [ 7296/12639]\n",
      "loss: 4.531046  [ 8512/12639]\n",
      "loss: 4.608711  [ 9728/12639]\n",
      "loss: 4.606512  [10944/12639]\n",
      "loss: 4.568074  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.614928 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 4.533770  [    0/12639]\n",
      "loss: 4.593468  [ 1216/12639]\n",
      "loss: 4.566530  [ 2432/12639]\n",
      "loss: 4.587604  [ 3648/12639]\n",
      "loss: 4.603284  [ 4864/12639]\n",
      "loss: 4.602628  [ 6080/12639]\n",
      "loss: 4.585735  [ 7296/12639]\n",
      "loss: 4.519000  [ 8512/12639]\n",
      "loss: 4.551831  [ 9728/12639]\n",
      "loss: 4.532878  [10944/12639]\n",
      "loss: 4.531412  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.608384 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 4.573231  [    0/12639]\n",
      "loss: 4.527064  [ 1216/12639]\n",
      "loss: 4.575766  [ 2432/12639]\n",
      "loss: 4.600787  [ 3648/12639]\n",
      "loss: 4.611753  [ 4864/12639]\n",
      "loss: 4.604991  [ 6080/12639]\n",
      "loss: 4.620338  [ 7296/12639]\n",
      "loss: 4.552942  [ 8512/12639]\n",
      "loss: 4.596238  [ 9728/12639]\n",
      "loss: 4.518053  [10944/12639]\n",
      "loss: 4.592601  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.608444 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 4.629361  [    0/12639]\n",
      "loss: 4.580015  [ 1216/12639]\n",
      "loss: 4.584582  [ 2432/12639]\n",
      "loss: 4.586772  [ 3648/12639]\n",
      "loss: 4.577013  [ 4864/12639]\n",
      "loss: 4.588564  [ 6080/12639]\n",
      "loss: 4.612121  [ 7296/12639]\n",
      "loss: 4.518394  [ 8512/12639]\n",
      "loss: 4.610220  [ 9728/12639]\n",
      "loss: 4.562268  [10944/12639]\n",
      "loss: 4.576799  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.609647 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 4.475652  [    0/12639]\n",
      "loss: 4.580617  [ 1216/12639]\n",
      "loss: 4.562908  [ 2432/12639]\n",
      "loss: 4.540659  [ 3648/12639]\n",
      "loss: 4.545054  [ 4864/12639]\n",
      "loss: 4.607257  [ 6080/12639]\n",
      "loss: 4.524509  [ 7296/12639]\n",
      "loss: 4.613845  [ 8512/12639]\n",
      "loss: 4.602750  [ 9728/12639]\n",
      "loss: 4.548737  [10944/12639]\n",
      "loss: 4.517658  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.614733 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 4.575964  [    0/12639]\n",
      "loss: 4.505832  [ 1216/12639]\n",
      "loss: 4.591327  [ 2432/12639]\n",
      "loss: 4.601013  [ 3648/12639]\n",
      "loss: 4.608381  [ 4864/12639]\n",
      "loss: 4.607611  [ 6080/12639]\n",
      "loss: 4.601106  [ 7296/12639]\n",
      "loss: 4.633650  [ 8512/12639]\n",
      "loss: 4.559959  [ 9728/12639]\n",
      "loss: 4.583982  [10944/12639]\n",
      "loss: 4.520288  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.610220 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 4.519071  [    0/12639]\n",
      "loss: 4.531523  [ 1216/12639]\n",
      "loss: 4.608564  [ 2432/12639]\n",
      "loss: 4.560883  [ 3648/12639]\n",
      "loss: 4.628682  [ 4864/12639]\n",
      "loss: 4.595297  [ 6080/12639]\n",
      "loss: 4.628655  [ 7296/12639]\n",
      "loss: 4.550917  [ 8512/12639]\n",
      "loss: 4.625575  [ 9728/12639]\n",
      "loss: 4.451960  [10944/12639]\n",
      "loss: 4.541086  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.610822 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 4.559235  [    0/12639]\n",
      "loss: 4.625806  [ 1216/12639]\n",
      "loss: 4.588616  [ 2432/12639]\n",
      "loss: 4.600334  [ 3648/12639]\n",
      "loss: 4.585907  [ 4864/12639]\n",
      "loss: 4.610831  [ 6080/12639]\n",
      "loss: 4.618164  [ 7296/12639]\n",
      "loss: 4.602004  [ 8512/12639]\n",
      "loss: 4.617588  [ 9728/12639]\n",
      "loss: 4.590882  [10944/12639]\n",
      "loss: 4.606122  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.620084 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 4.492626  [    0/12639]\n",
      "loss: 4.526529  [ 1216/12639]\n",
      "loss: 4.585821  [ 2432/12639]\n",
      "loss: 4.470844  [ 3648/12639]\n",
      "loss: 4.609912  [ 4864/12639]\n",
      "loss: 4.526074  [ 6080/12639]\n",
      "loss: 4.513346  [ 7296/12639]\n",
      "loss: 4.611970  [ 8512/12639]\n",
      "loss: 4.613779  [ 9728/12639]\n",
      "loss: 4.472121  [10944/12639]\n",
      "loss: 4.547755  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.618774 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 4.489786  [    0/12639]\n",
      "loss: 4.609529  [ 1216/12639]\n",
      "loss: 4.521395  [ 2432/12639]\n",
      "loss: 4.514079  [ 3648/12639]\n",
      "loss: 4.603647  [ 4864/12639]\n",
      "loss: 4.586729  [ 6080/12639]\n",
      "loss: 4.589513  [ 7296/12639]\n",
      "loss: 4.623728  [ 8512/12639]\n",
      "loss: 4.613410  [ 9728/12639]\n",
      "loss: 4.391065  [10944/12639]\n",
      "loss: 4.580122  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.606107 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 4.423357  [    0/12639]\n",
      "loss: 4.585068  [ 1216/12639]\n",
      "loss: 4.590029  [ 2432/12639]\n",
      "loss: 4.581101  [ 3648/12639]\n",
      "loss: 4.529981  [ 4864/12639]\n",
      "loss: 4.585438  [ 6080/12639]\n",
      "loss: 4.612488  [ 7296/12639]\n",
      "loss: 4.535297  [ 8512/12639]\n",
      "loss: 4.594807  [ 9728/12639]\n",
      "loss: 4.511552  [10944/12639]\n",
      "loss: 4.590786  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.602804 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 4.599308  [    0/12639]\n",
      "loss: 4.592337  [ 1216/12639]\n",
      "loss: 4.561789  [ 2432/12639]\n",
      "loss: 4.540192  [ 3648/12639]\n",
      "loss: 4.596413  [ 4864/12639]\n",
      "loss: 4.595075  [ 6080/12639]\n",
      "loss: 4.596866  [ 7296/12639]\n",
      "loss: 4.624534  [ 8512/12639]\n",
      "loss: 4.623600  [ 9728/12639]\n",
      "loss: 4.584615  [10944/12639]\n",
      "loss: 4.587118  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.614363 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 4.614986  [    0/12639]\n",
      "loss: 4.539412  [ 1216/12639]\n",
      "loss: 4.605906  [ 2432/12639]\n",
      "loss: 4.461066  [ 3648/12639]\n",
      "loss: 4.607416  [ 4864/12639]\n",
      "loss: 4.587317  [ 6080/12639]\n",
      "loss: 4.514429  [ 7296/12639]\n",
      "loss: 4.603158  [ 8512/12639]\n",
      "loss: 4.582184  [ 9728/12639]\n",
      "loss: 4.537459  [10944/12639]\n",
      "loss: 4.569350  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.604393 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 4.599703  [    0/12639]\n",
      "loss: 4.583211  [ 1216/12639]\n",
      "loss: 4.600707  [ 2432/12639]\n",
      "loss: 4.575110  [ 3648/12639]\n",
      "loss: 4.491753  [ 4864/12639]\n",
      "loss: 4.603031  [ 6080/12639]\n",
      "loss: 4.519792  [ 7296/12639]\n",
      "loss: 4.581414  [ 8512/12639]\n",
      "loss: 4.507822  [ 9728/12639]\n",
      "loss: 4.530229  [10944/12639]\n",
      "loss: 4.584090  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.623094 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 4.768196  [    0/12639]\n",
      "loss: 4.529647  [ 1216/12639]\n",
      "loss: 4.516222  [ 2432/12639]\n",
      "loss: 4.610448  [ 3648/12639]\n",
      "loss: 4.611712  [ 4864/12639]\n",
      "loss: 4.491657  [ 6080/12639]\n",
      "loss: 4.585260  [ 7296/12639]\n",
      "loss: 4.584416  [ 8512/12639]\n",
      "loss: 4.608296  [ 9728/12639]\n",
      "loss: 4.523303  [10944/12639]\n",
      "loss: 4.580610  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.621021 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 4.482424  [    0/12639]\n",
      "loss: 4.430149  [ 1216/12639]\n",
      "loss: 4.496006  [ 2432/12639]\n",
      "loss: 4.578861  [ 3648/12639]\n",
      "loss: 4.606230  [ 4864/12639]\n",
      "loss: 4.614376  [ 6080/12639]\n",
      "loss: 4.574121  [ 7296/12639]\n",
      "loss: 4.567558  [ 8512/12639]\n",
      "loss: 4.536924  [ 9728/12639]\n",
      "loss: 4.484297  [10944/12639]\n",
      "loss: 4.582678  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.638697 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 4.321620  [    0/12639]\n",
      "loss: 4.535473  [ 1216/12639]\n",
      "loss: 4.448417  [ 2432/12639]\n",
      "loss: 4.581626  [ 3648/12639]\n",
      "loss: 4.538009  [ 4864/12639]\n",
      "loss: 4.586959  [ 6080/12639]\n",
      "loss: 4.574207  [ 7296/12639]\n",
      "loss: 4.501362  [ 8512/12639]\n",
      "loss: 4.561120  [ 9728/12639]\n",
      "loss: 4.607809  [10944/12639]\n",
      "loss: 4.689627  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.615030 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 4.476507  [    0/12639]\n",
      "loss: 4.547324  [ 1216/12639]\n",
      "loss: 4.487939  [ 2432/12639]\n",
      "loss: 4.575013  [ 3648/12639]\n",
      "loss: 4.587391  [ 4864/12639]\n",
      "loss: 4.461249  [ 6080/12639]\n",
      "loss: 4.544929  [ 7296/12639]\n",
      "loss: 4.607881  [ 8512/12639]\n",
      "loss: 4.618443  [ 9728/12639]\n",
      "loss: 4.600139  [10944/12639]\n",
      "loss: 4.592189  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 4.631876 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 4.517861  [    0/12639]\n",
      "loss: 4.690501  [ 1216/12639]\n",
      "loss: 4.600486  [ 2432/12639]\n",
      "loss: 4.601179  [ 3648/12639]\n",
      "loss: 4.545944  [ 4864/12639]\n",
      "loss: 4.437332  [ 6080/12639]\n",
      "loss: 4.500853  [ 7296/12639]\n",
      "loss: 4.613972  [ 8512/12639]\n",
      "loss: 4.592139  [ 9728/12639]\n",
      "loss: 4.582765  [10944/12639]\n",
      "loss: 4.573309  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.643287 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 4.594375  [    0/12639]\n",
      "loss: 4.593706  [ 1216/12639]\n",
      "loss: 4.611200  [ 2432/12639]\n",
      "loss: 4.579342  [ 3648/12639]\n",
      "loss: 4.484553  [ 4864/12639]\n",
      "loss: 4.559255  [ 6080/12639]\n",
      "loss: 4.583572  [ 7296/12639]\n",
      "loss: 4.594325  [ 8512/12639]\n",
      "loss: 4.569394  [ 9728/12639]\n",
      "loss: 4.580423  [10944/12639]\n",
      "loss: 4.444464  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.639833 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 4.537297  [    0/12639]\n",
      "loss: 4.509858  [ 1216/12639]\n",
      "loss: 4.542965  [ 2432/12639]\n",
      "loss: 4.433346  [ 3648/12639]\n",
      "loss: 4.578539  [ 4864/12639]\n",
      "loss: 4.588416  [ 6080/12639]\n",
      "loss: 4.608311  [ 7296/12639]\n",
      "loss: 4.612910  [ 8512/12639]\n",
      "loss: 4.515692  [ 9728/12639]\n",
      "loss: 4.599146  [10944/12639]\n",
      "loss: 4.439217  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.639749 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 4.522731  [    0/12639]\n",
      "loss: 4.494984  [ 1216/12639]\n",
      "loss: 4.464942  [ 2432/12639]\n",
      "loss: 4.606717  [ 3648/12639]\n",
      "loss: 4.592475  [ 4864/12639]\n",
      "loss: 4.602699  [ 6080/12639]\n",
      "loss: 4.652524  [ 7296/12639]\n",
      "loss: 4.570055  [ 8512/12639]\n",
      "loss: 4.604899  [ 9728/12639]\n",
      "loss: 4.578388  [10944/12639]\n",
      "loss: 4.558118  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.610383 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 4.616641  [    0/12639]\n",
      "loss: 5.105486  [ 1216/12639]\n",
      "loss: 4.552758  [ 2432/12639]\n",
      "loss: 4.536757  [ 3648/12639]\n",
      "loss: 4.573981  [ 4864/12639]\n",
      "loss: 4.517381  [ 6080/12639]\n",
      "loss: 4.647224  [ 7296/12639]\n",
      "loss: 4.500011  [ 8512/12639]\n",
      "loss: 4.511834  [ 9728/12639]\n",
      "loss: 4.506650  [10944/12639]\n",
      "loss: 4.589016  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.607567 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 4.583121  [    0/12639]\n",
      "loss: 4.578102  [ 1216/12639]\n",
      "loss: 4.566116  [ 2432/12639]\n",
      "loss: 4.510794  [ 3648/12639]\n",
      "loss: 4.526611  [ 4864/12639]\n",
      "loss: 4.595598  [ 6080/12639]\n",
      "loss: 4.510805  [ 7296/12639]\n",
      "loss: 4.578977  [ 8512/12639]\n",
      "loss: 4.579314  [ 9728/12639]\n",
      "loss: 4.541659  [10944/12639]\n",
      "loss: 4.556787  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 4.634474 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 4.436521  [    0/12639]\n",
      "loss: 4.539268  [ 1216/12639]\n",
      "loss: 4.598165  [ 2432/12639]\n",
      "loss: 4.528495  [ 3648/12639]\n",
      "loss: 4.635660  [ 4864/12639]\n",
      "loss: 4.620185  [ 6080/12639]\n",
      "loss: 4.604224  [ 7296/12639]\n",
      "loss: 4.522926  [ 8512/12639]\n",
      "loss: 4.570472  [ 9728/12639]\n",
      "loss: 4.603760  [10944/12639]\n",
      "loss: 4.613995  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 4.587718 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 4.574589  [    0/12639]\n",
      "loss: 4.531060  [ 1216/12639]\n",
      "loss: 4.520411  [ 2432/12639]\n",
      "loss: 4.645864  [ 3648/12639]\n",
      "loss: 4.600661  [ 4864/12639]\n",
      "loss: 4.416871  [ 6080/12639]\n",
      "loss: 4.487703  [ 7296/12639]\n",
      "loss: 4.526092  [ 8512/12639]\n",
      "loss: 4.461740  [ 9728/12639]\n",
      "loss: 4.560153  [10944/12639]\n",
      "loss: 4.509637  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.613103 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 4.617705  [    0/12639]\n",
      "loss: 4.589210  [ 1216/12639]\n",
      "loss: 4.591446  [ 2432/12639]\n",
      "loss: 4.548550  [ 3648/12639]\n",
      "loss: 4.448516  [ 4864/12639]\n",
      "loss: 4.579733  [ 6080/12639]\n",
      "loss: 4.613257  [ 7296/12639]\n",
      "loss: 4.490438  [ 8512/12639]\n",
      "loss: 4.595502  [ 9728/12639]\n",
      "loss: 4.601629  [10944/12639]\n",
      "loss: 4.506089  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.633989 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 4.624169  [    0/12639]\n",
      "loss: 4.614648  [ 1216/12639]\n",
      "loss: 4.568704  [ 2432/12639]\n",
      "loss: 4.533092  [ 3648/12639]\n",
      "loss: 4.596269  [ 4864/12639]\n",
      "loss: 4.594355  [ 6080/12639]\n",
      "loss: 4.557192  [ 7296/12639]\n",
      "loss: 4.565626  [ 8512/12639]\n",
      "loss: 4.453942  [ 9728/12639]\n",
      "loss: 4.527024  [10944/12639]\n",
      "loss: 4.628520  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.628388 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 4.602264  [    0/12639]\n",
      "loss: 4.590169  [ 1216/12639]\n",
      "loss: 4.458761  [ 2432/12639]\n",
      "loss: 4.464283  [ 3648/12639]\n",
      "loss: 4.484518  [ 4864/12639]\n",
      "loss: 4.581705  [ 6080/12639]\n",
      "loss: 4.575305  [ 7296/12639]\n",
      "loss: 4.441496  [ 8512/12639]\n",
      "loss: 4.530358  [ 9728/12639]\n",
      "loss: 4.590155  [10944/12639]\n",
      "loss: 4.498573  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.614325 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 4.509797  [    0/12639]\n",
      "loss: 4.584885  [ 1216/12639]\n",
      "loss: 4.512323  [ 2432/12639]\n",
      "loss: 4.637774  [ 3648/12639]\n",
      "loss: 4.601085  [ 4864/12639]\n",
      "loss: 4.550667  [ 6080/12639]\n",
      "loss: 4.485539  [ 7296/12639]\n",
      "loss: 4.554492  [ 8512/12639]\n",
      "loss: 4.546780  [ 9728/12639]\n",
      "loss: 4.550168  [10944/12639]\n",
      "loss: 4.516482  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 4.606292 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 4.609023  [    0/12639]\n",
      "loss: 4.510671  [ 1216/12639]\n",
      "loss: 4.533015  [ 2432/12639]\n",
      "loss: 4.468347  [ 3648/12639]\n",
      "loss: 4.552166  [ 4864/12639]\n",
      "loss: 4.439534  [ 6080/12639]\n",
      "loss: 4.478793  [ 7296/12639]\n",
      "loss: 4.589628  [ 8512/12639]\n",
      "loss: 4.616538  [ 9728/12639]\n",
      "loss: 4.618447  [10944/12639]\n",
      "loss: 4.573429  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.611478 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 4.619971  [    0/12639]\n",
      "loss: 4.599161  [ 1216/12639]\n",
      "loss: 4.464996  [ 2432/12639]\n",
      "loss: 4.550056  [ 3648/12639]\n",
      "loss: 4.545278  [ 4864/12639]\n",
      "loss: 4.583541  [ 6080/12639]\n",
      "loss: 4.530454  [ 7296/12639]\n",
      "loss: 4.567037  [ 8512/12639]\n",
      "loss: 4.604797  [ 9728/12639]\n",
      "loss: 4.462134  [10944/12639]\n",
      "loss: 4.484905  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 4.620183 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 4.583822  [    0/12639]\n",
      "loss: 4.531940  [ 1216/12639]\n",
      "loss: 4.606379  [ 2432/12639]\n",
      "loss: 4.581908  [ 3648/12639]\n",
      "loss: 4.457078  [ 4864/12639]\n",
      "loss: 4.565924  [ 6080/12639]\n",
      "loss: 4.531985  [ 7296/12639]\n",
      "loss: 4.675432  [ 8512/12639]\n",
      "loss: 4.565825  [ 9728/12639]\n",
      "loss: 4.560265  [10944/12639]\n",
      "loss: 4.597977  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.681115 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 4.416624  [    0/12639]\n",
      "loss: 4.552686  [ 1216/12639]\n",
      "loss: 4.511871  [ 2432/12639]\n",
      "loss: 4.625601  [ 3648/12639]\n",
      "loss: 4.667445  [ 4864/12639]\n",
      "loss: 4.397875  [ 6080/12639]\n",
      "loss: 4.454895  [ 7296/12639]\n",
      "loss: 4.484674  [ 8512/12639]\n",
      "loss: 4.570521  [ 9728/12639]\n",
      "loss: 4.601947  [10944/12639]\n",
      "loss: 4.606779  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 4.635999 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 4.553525  [    0/12639]\n",
      "loss: 4.484131  [ 1216/12639]\n",
      "loss: 4.520369  [ 2432/12639]\n",
      "loss: 4.521098  [ 3648/12639]\n",
      "loss: 4.611206  [ 4864/12639]\n",
      "loss: 4.529884  [ 6080/12639]\n",
      "loss: 4.563118  [ 7296/12639]\n",
      "loss: 4.595376  [ 8512/12639]\n",
      "loss: 4.566871  [ 9728/12639]\n",
      "loss: 4.597589  [10944/12639]\n",
      "loss: 4.571083  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.641754 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 4.522341  [    0/12639]\n",
      "loss: 4.519995  [ 1216/12639]\n",
      "loss: 4.447690  [ 2432/12639]\n",
      "loss: 4.526574  [ 3648/12639]\n",
      "loss: 4.550327  [ 4864/12639]\n",
      "loss: 4.626682  [ 6080/12639]\n",
      "loss: 4.541831  [ 7296/12639]\n",
      "loss: 4.597951  [ 8512/12639]\n",
      "loss: 4.508402  [ 9728/12639]\n",
      "loss: 4.506638  [10944/12639]\n",
      "loss: 4.465730  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 4.631760 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 4.432098  [    0/12639]\n",
      "loss: 4.464934  [ 1216/12639]\n",
      "loss: 4.545660  [ 2432/12639]\n",
      "loss: 4.608280  [ 3648/12639]\n",
      "loss: 4.509843  [ 4864/12639]\n",
      "loss: 4.561669  [ 6080/12639]\n",
      "loss: 4.496523  [ 7296/12639]\n",
      "loss: 4.546313  [ 8512/12639]\n",
      "loss: 4.545197  [ 9728/12639]\n",
      "loss: 4.444673  [10944/12639]\n",
      "loss: 4.537284  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 4.621222 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 4.405194  [    0/12639]\n",
      "loss: 4.526071  [ 1216/12639]\n",
      "loss: 4.664428  [ 2432/12639]\n",
      "loss: 4.543054  [ 3648/12639]\n",
      "loss: 4.739513  [ 4864/12639]\n",
      "loss: 4.612045  [ 6080/12639]\n",
      "loss: 4.564754  [ 7296/12639]\n",
      "loss: 4.527933  [ 8512/12639]\n",
      "loss: 4.595512  [ 9728/12639]\n",
      "loss: 4.618122  [10944/12639]\n",
      "loss: 4.630133  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 4.632249 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 4.601659  [    0/12639]\n",
      "loss: 4.399851  [ 1216/12639]\n",
      "loss: 4.544269  [ 2432/12639]\n",
      "loss: 4.608929  [ 3648/12639]\n",
      "loss: 4.605067  [ 4864/12639]\n",
      "loss: 4.580348  [ 6080/12639]\n",
      "loss: 4.546693  [ 7296/12639]\n",
      "loss: 4.526012  [ 8512/12639]\n",
      "loss: 4.516171  [ 9728/12639]\n",
      "loss: 4.631134  [10944/12639]\n",
      "loss: 4.615479  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 4.625801 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 4.599825  [    0/12639]\n",
      "loss: 4.550846  [ 1216/12639]\n",
      "loss: 4.576880  [ 2432/12639]\n",
      "loss: 4.589002  [ 3648/12639]\n",
      "loss: 4.532047  [ 4864/12639]\n",
      "loss: 4.522218  [ 6080/12639]\n",
      "loss: 4.522208  [ 7296/12639]\n",
      "loss: 4.457328  [ 8512/12639]\n",
      "loss: 4.536455  [ 9728/12639]\n",
      "loss: 4.441377  [10944/12639]\n",
      "loss: 4.582905  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.604751 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 4.595632  [    0/12639]\n",
      "loss: 4.574811  [ 1216/12639]\n",
      "loss: 4.579144  [ 2432/12639]\n",
      "loss: 4.647126  [ 3648/12639]\n",
      "loss: 4.636343  [ 4864/12639]\n",
      "loss: 4.601353  [ 6080/12639]\n",
      "loss: 4.620544  [ 7296/12639]\n",
      "loss: 4.613937  [ 8512/12639]\n",
      "loss: 4.590485  [ 9728/12639]\n",
      "loss: 4.589536  [10944/12639]\n",
      "loss: 4.601643  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.605503 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 4.583746  [    0/12639]\n",
      "loss: 4.594638  [ 1216/12639]\n",
      "loss: 4.587811  [ 2432/12639]\n",
      "loss: 4.599127  [ 3648/12639]\n",
      "loss: 4.624753  [ 4864/12639]\n",
      "loss: 4.602712  [ 6080/12639]\n",
      "loss: 4.628144  [ 7296/12639]\n",
      "loss: 4.607631  [ 8512/12639]\n",
      "loss: 4.588846  [ 9728/12639]\n",
      "loss: 4.569451  [10944/12639]\n",
      "loss: 4.624084  [12160/12639]\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 4.606155 \n",
      "\n",
      "Done!\n",
      "Writing 'out_dwt.stdout' (str) to file '../result/Butterfly_haar.txt'.\n"
     ]
    }
   ],
   "source": [
    "out_dwt()\n",
    "%store out_dwt.stdout >../result/Butterfly_haar.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_epoch_info(\"../result/Butterfly_original.txt\", [\"../result/Butterfly_haar.txt\"], \"Butterflies\", [\"haar\"])\n",
    "ax.set_xticks([0] + [5*i - 1 for i in range(1, 21)])\n",
    "ax.set_ylabel(\"Test Accuracy (%)\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "fig.suptitle(\"Butterfly Dataset Preliminary Results (CNN)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "329387261a1368c4701080926016bc1dc31e3de51bf7c0cc9b7a31283fa2308a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
